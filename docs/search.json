[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "YCT Productivity - Redd Counts",
    "section": "",
    "text": "1 Introduction\nThis book describes efforts to understand how changing climate (temperature and flow regimes) and dam management practices affect population productivity of Yellowstone cutthroat trout (YCT) in the upper Snake River watershed, Wyoming, USA. We use a Ricker stock-recruitment model fit to long-term redd count data from 13 spring creek spawning populations that migrate between natal spring creeks for spawning and the mainstem Snake River for rearing. All redd count data were collected by the Wyoming Game and Fish Department Jackson Fisheries Management Team.\nThis information is preliminary or provisional and is subject to revision. It is being provided to meet the need for timely best science. The information has not received final approval by the U.S. Geological Survey (USGS) and is provided on the condition that neither the USGS nor the U.S. Government shall be held liable for any damages resulting from the authorized or unauthorized use of the information.\nProject team: Jeff Baldock and Annika Walters\n\n\nSession Information\n\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.3 (2025-02-28 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Denver\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.3    fastmap_1.2.0     cli_3.6.3        \n [5] tools_4.4.3       htmltools_0.5.8.1 rstudioapi_0.17.1 rmarkdown_2.29   \n [9] knitr_1.48        jsonlite_1.8.9    xfun_0.49         digest_0.6.37    \n[13] rlang_1.1.4       evaluate_1.0.1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "FlowTemp_Covariates.html",
    "href": "FlowTemp_Covariates.html",
    "title": "2  Environmental Covariates",
    "section": "",
    "text": "2.1 Streamflow\nPurpose: Generate annual covariate data describing seasonal air temperature, natural flow regimes, and managed flow regimes.\nSpecify USGS streamflow monitoring sites and map:\nCode\nsites &lt;- c(\"13011000\", # Snake at Moran\n           \"13018750\", # Snake below Flat\n           \"13027500\", # Salt\n           \"13023000\", # Greys\n           \"13011900\", # Buffalo Fork\n           \"13015000\", # Gros Ventre - Zenith\n           \"13014500\", # Gros Ventre - Kelly\n           \"13018350\", # Flat - below Cache\n           \"13018300\", # Cache \n           \"13016450\", # Fish\n           \"13011820\") # Blackrock\nsite.info &lt;- readNWISsite(sites)[,c(1:2,7,8,18)] # get site info\nnames(site.info) &lt;- c(\"agency\", \"logger\", \"lat\", \"long\", \"site\") # rename columns \nsite.info$sitesimp &lt;- c(\"SnakeMoran\", \"Blackrock\", \"BuffaloFork\", \"GrosVentreKelly\", \"GrosVentreZenith\", \"Fish\", \"Cache\", \"FlatBeCache\", \"SnakeBeFlat\", \"Greys\", \"Salt\")\nmapview(st_as_sf(site.info, coords = c(\"long\", \"lat\"), crs = \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84\"))\nExtract daily mean discharge and temp data from USGS NWIS and get date range for each gage:\nCode\nflow &lt;- readNWISdata(sites = sites, parameterCd = c(\"00060\"), service = \"dv\", startDate = \"1960-01-01\", endDate = \"2023-09-01\")\nnames(flow) &lt;- c(\"agency\", \"logger\", \"date\", \"q\", \"x2\", \"x3\")\nflow %&gt;% group_by(logger) %&gt;% summarize(mindate = min(date), maxdate = max(date))\n\n\n# A tibble: 11 × 3\n   logger   mindate             maxdate            \n   &lt;chr&gt;    &lt;dttm&gt;              &lt;dttm&gt;             \n 1 13011000 1960-01-01 00:00:00 2023-09-01 00:00:00\n 2 13011820 2017-10-27 00:00:00 2023-09-01 00:00:00\n 3 13011900 1965-09-22 00:00:00 2023-09-01 00:00:00\n 4 13014500 2008-04-01 00:00:00 2023-09-01 00:00:00\n 5 13015000 1987-10-01 00:00:00 2023-09-01 00:00:00\n 6 13016450 1994-03-24 00:00:00 2023-09-01 00:00:00\n 7 13018300 1962-07-01 00:00:00 2023-09-01 00:00:00\n 8 13018350 1989-04-01 00:00:00 2023-09-01 00:00:00\n 9 13018750 1975-11-12 00:00:00 2023-09-01 00:00:00\n10 13023000 1960-01-01 00:00:00 2023-09-01 00:00:00\n11 13027500 1960-01-01 00:00:00 2023-09-01 00:00:00\nSome data manipulation:\nCode\nflow &lt;- tibble(flow %&gt;% dplyr::select(logger, date, q) %&gt;% mutate(date = as_date(date), doy = yday(date), month = month(date), year = year(date)))\nflow$broodyr &lt;- NA # create brood year variable\nflow$broodyr &lt;- ifelse(flow$month &gt;= 9 & flow$month &lt;= 12, flow$year, flow$year-1)\nflow &lt;- flow %&gt;% filter(!broodyr %in% c(1959,2023)) # drop incomplete brood years\nflow &lt;- flow %&gt;% left_join(site.info %&gt;% select(logger, sitesimp))\nView raw data\nCode\nflow %&gt;% ggplot() + geom_line(aes(x = date, y = q)) + facet_wrap(~ sitesimp, scales = \"free_y\")\nSpread by date and calculate and explore correlation between dam release and natural flow:\nCode\nflow2 &lt;- flow %&gt;% select(-logger) %&gt;% spread(sitesimp, q) %&gt;% mutate(SnakeNat = SnakeBeFlat - SnakeMoran,\n                                                                     FlatNat = FlatBeCache - Cache,\n                                                                     BuffNat = BuffaloFork - Blackrock)\n# plot(SnakeNat ~ date, flow2, type = \"l\", xlim = c(date(\"2018-01-01\"), date(\"2022-01-01\")))\n# plot(FlatNat ~ date, flow2, type = \"l\", xlim = c(date(\"2010-01-01\"), date(\"2020-01-01\")))\n# plot(BuffNat ~ date, flow2, type = \"l\", xlim = c(date(\"2018-01-01\"), date(\"2022-01-01\")))\n# plot(Fish ~ date, flow2, type = \"l\", xlim = c(date(\"2018-01-01\"), date(\"2022-01-01\")))\nplot(SnakeNat ~ SnakeMoran, flow2)\n\n\n\n\n\n\n\n\n\nCode\ncor.test(flow2$SnakeNat, flow2$SnakeMoran)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  flow2$SnakeNat and flow2$SnakeMoran\nt = 95.373, df = 17458, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5754375 0.5949431\nsample estimates:\n     cor \n0.585275\nCalculate first-differenced daily flow after log transform, rate of daily change in flow per Ward et al. 2015, Global Change Biology (enables calculation of flow variability)\nCode\nflow2 &lt;- flow2 %&gt;% mutate(varJLD = lead(log(SnakeMoran)) - log(SnakeMoran),\n                          varSnakeNat = lead(log(SnakeNat)) - log(SnakeNat),\n                          varSnakeBeFlat = lead(log(SnakeBeFlat)) - log(SnakeBeFlat),\n                          varSalt = lead(log(Salt)) - log(Salt),\n                          varBuff = lead(log(BuffNat)) - log(BuffNat),\n                          varFlat = lead(log(FlatNat)) - log(FlatNat),\n                          varGVK = lead(log(GrosVentreKelly)) - log(GrosVentreKelly),\n                          varGreys = lead(log(Greys)) - log(Greys),\n                          varFish = lead(log(Fish)) - log(Fish)) \n\nplot(varGreys ~ date, flow2 %&gt;% filter(broodyr %in% c(2021)), type = \"l\")\nCalculate day of brood year\nCode\ndlist1 &lt;- list()\nyrs &lt;- unique(flow2$broodyr)\nfor (i in 1:length(yrs)) {\n  d &lt;- filter(flow2, broodyr == yrs[i])\n  d$bydoy &lt;- c(1:dim(d)[1])\n  dlist1[[i]] &lt;- d\n}\nflow3 &lt;- bind_rows(dlist1)\nGather by site\nCode\nflow4 &lt;- flow3 %&gt;% \n  select(date, doy, month, year, broodyr, bydoy, SnakeBeFlat, SnakeMoran, SnakeNat, Salt, GrosVentreKelly, Greys, FlatNat, Fish, BuffNat) %&gt;% \n  rename(GrosVentre = GrosVentreKelly, Flat = FlatNat, Buffalo = BuffNat) %&gt;%\n  gather(key = \"site\", value = \"flow_cfs\", 7:15)\nflow5 &lt;- flow3 %&gt;% \n  select(date, doy, month, year, broodyr, bydoy, varSnakeBeFlat, varJLD, varSnakeNat, varSalt, varGVK, varGreys, varFlat, varFish, varBuff) %&gt;% \n  rename(SnakeBeFlat = varSnakeBeFlat, SnakeMoran = varJLD, SnakeNat = varSnakeNat, Salt = varSalt, GrosVentre = varGVK, Greys = varGreys, Flat = varFlat, Fish = varFish, Buffalo = varBuff) %&gt;%\n  gather(key = \"site\", value = \"flow_var\", 7:15)\nflow6 &lt;- flow4 %&gt;% left_join(flow5)\nPlot daily proportion of flow from JLD vs Natural\nCode\npar(mar = c(4,5,1,1), mgp = c(2.5,1,0))\nflowpr &lt;- flow2 %&gt;% \n  select(date, doy, month, year, broodyr, SnakeBeFlat, SnakeMoran, SnakeNat) %&gt;% \n  drop_na() %&gt;% mutate(PrJLD = SnakeMoran / SnakeBeFlat) %&gt;% group_by(doy) %&gt;% \n  summarize(minpr = min(PrJLD), q25pr = quantile(PrJLD, probs = 0.25), medpr = median(PrJLD), meanpr = mean(PrJLD), q75pr = quantile(PrJLD, probs = 0.75), maxpr = max(PrJLD))\nrange(flowpr$meanpr)\n\n\n[1] 0.2296375 0.6438328\n\n\nCode\nplot(medpr ~ doy, flowpr, type = \"n\", ylim = c(0,1), xlab = \"\", ylab = \"Proportional contribution of JLD release to total flow\\n(Snake Moran / Snake Below Flat)\", axes = F)\naxis(1, at = c(1,61,122,183,245,306,367), labels = c(\"Jan\",\"Mar\",\"May\",\"Jul\",\"Sep\",\"Nov\",\"Jan\"))\naxis(2)\nbox()\npolygon(x = c(flowpr$doy, rev(flowpr$doy)), y = c(flowpr$minpr, rev(flowpr$maxpr)), col = \"grey80\", border = NA)\npolygon(x = c(flowpr$doy, rev(flowpr$doy)), y = c(flowpr$q25pr, rev(flowpr$q75pr)), col = \"grey60\", border = NA)\n#lines(meanpr ~ doy, flowpr, lwd = 3)\nlines(medpr ~ doy, flowpr, lwd = 3)\nlegend(x = -15, y = 1.05, legend = c(\"Median\"), lwd = c(3), bty = \"n\")\nlegend(x = 3, y = 0.99, legend = c(\"IQR\", \"Range\"), fill = c(\"grey60\",\"grey80\"), bty = \"n\")\nPlot natural (blue), JLD (red), and combined mean daily flow (grey) for each year:\nCode\nd &lt;- flow6 %&gt;% \n  filter(site %in% c(\"SnakeBeFlat\", \"SnakeMoran\", \"SnakeNat\")) %&gt;% \n  select(bydoy, broodyr, site, flow_cfs) %&gt;%\n  spread(site, flow_cfs)\ndd &lt;- d %&gt;% mutate(diff = (SnakeMoran + SnakeNat) - SnakeBeFlat)\nunique(dd$diff) # check that the flow components sum correctly\n\n\n[1] NA  0\nCode\nd %&gt;% filter(broodyr %in% c(1980:1999)) %&gt;%\n  ggplot(aes(x = bydoy)) +\n  geom_line(aes(y = SnakeBeFlat), color = \"grey30\") +\n  geom_line(aes(y = SnakeMoran), color = \"red\") +\n  geom_line(aes(y = SnakeNat), color = \"blue\") +\n  facet_wrap(~ broodyr) +\n  theme_bw() + theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\nCode\nd %&gt;% filter(broodyr %in% c(2000:2024)) %&gt;%\n  ggplot(aes(x = bydoy)) +\n  geom_line(aes(y = SnakeBeFlat), color = \"grey30\") +\n  geom_line(aes(y = SnakeMoran), color = \"red\") +\n  geom_line(aes(y = SnakeNat), color = \"blue\") +\n  facet_wrap(~ broodyr)  +\n  theme_bw() + theme(panel.grid = element_blank())\nTime series of cv flows sensu Ward et al. (2015):\nCode\ndd &lt;- d %&gt;% \n  group_by(bydoy) %&gt;% \n  summarize(muSBF = mean(SnakeBeFlat, na.rm = TRUE), sdSBF = sd(SnakeBeFlat, na.rm = TRUE), cvSBF = muSBF/sdSBF,\n            muSMo = mean(SnakeMoran, na.rm = TRUE), sdSMo = sd(SnakeMoran, na.rm = TRUE), cvSMo = muSMo/sdSMo,\n            muSNa = mean(SnakeNat, na.rm = TRUE), sdSNa = sd(SnakeNat, na.rm = TRUE), cvSNa = muSNa/sdSNa)\nggplot(dd, aes(x = bydoy)) + \n  geom_line(aes(y = cvSBF), color = \"grey30\") +\n  geom_line(aes(y = cvSMo), color = \"red\") +\n  geom_line(aes(y = cvSNa), color = \"blue\") +\n  theme_bw() + theme(panel.grid = element_blank())",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environmental Covariates</span>"
    ]
  },
  {
    "objectID": "FlowTemp_Covariates.html#temperature",
    "href": "FlowTemp_Covariates.html#temperature",
    "title": "2  Environmental Covariates",
    "section": "2.2 Temperature",
    "text": "2.2 Temperature\nDownload and organize air temperature data.\nLoad NOAA air temperature data for Moose, WY. Downloaded from https://www.ncdc.noaa.gov/cdo-web/search, 19 Sept 2023\n\n\nCode\nair_moose &lt;- read_csv(\"Data/NOAA_MooseWy_Climate_1960-2023.csv\") %&gt;% \n  select(STATION, DATE, TMAX, TMIN) %&gt;% \n  rowwise() %&gt;% \n  mutate(tmean = mean(c(TMAX, TMIN)), site = \"moose\") %&gt;% \n  rename(station = STATION, date = DATE, tmax = TMAX, tmin = TMIN) %&gt;%\n  select(station, site, date, tmin, tmax, tmean)\n\n# add rows for days with no observations/data, and linearly interpolation to fill gaps\nrDOY &lt;- range(air_moose$date)\nair_moose_com &lt;- tibble(station = unique(air_moose$station),\n                        site = \"moose\",\n                        date = seq(from = rDOY[1], to = rDOY[2], by = 1))\nair_moose_com &lt;- air_moose_com %&gt;% left_join(air_moose)\nair_moose_com$tmean_int &lt;- na.approx(air_moose_com$tmean)\n\n\nLoad NOAA air temperature data for Afton, WY. Downloaded from https://www.ncdc.noaa.gov/cdo-web/search, 19 Sept 2023\n\n\nCode\nair_afton &lt;- read_csv(\"Data/NOAA_AftonWy_Climate_1960-2023.csv\") %&gt;% \n  select(STATION, DATE, TMAX, TMIN) %&gt;% \n  rowwise() %&gt;% \n  mutate(tmean = mean(c(TMAX, TMIN)), site = \"afton\") %&gt;% \n  rename(station = STATION, date = DATE, tmax = TMAX, tmin = TMIN) %&gt;%\n  select(station, site, date, tmin, tmax, tmean)\n\n# add rows for days with no observations/data, and linearly interpolation to fill gaps\nrDOY &lt;- range(air_afton$date)\nair_afton_com &lt;- tibble(station = unique(air_afton$station),\n                        site = \"afton\",\n                        date = seq(from = rDOY[1], to = rDOY[2], by = 1))\nair_afton_com &lt;- air_afton_com %&gt;% left_join(air_afton)\nair_afton_com$tmean_int &lt;- na.approx(air_afton_com$tmean)\n\n\nBind and plot time series and correlation:\n\n\nCode\nairtemp &lt;- bind_rows(air_moose_com, air_afton_com) #%&gt;% mutate(int = ifelse(is.na(tmean), 1, 0))\nairtemp %&gt;% ggplot() + geom_line(aes(x = date, y = tmax)) + facet_wrap(~ site, nrow = 2)\n\n\n\n\n\n\n\n\n\nCode\nplot(airtemp$tmean[airtemp$site == \"moose\"] ~ airtemp$tmean[airtemp$site == \"afton\"])\nabline(a = 0, b = 1, col = \"red\")\n\n\n\n\n\n\n\n\n\nSet brood year and day of brood year:\n\n\nCode\n# brood year\nairtemp &lt;- airtemp %&gt;% mutate(year = year(date), month = month(date), yday = yday(date))\nairtemp$broodyr &lt;- NA # create brood year variable\nairtemp$broodyr &lt;- ifelse(airtemp$month &gt;= 9 & airtemp$month &lt;= 12, airtemp$year, airtemp$year-1)\nairtemp &lt;- airtemp %&gt;% filter(!broodyr %in% c(1959,2023)) # drop incomplete brood years\n\n# calculate day of brood year\ndlist1 &lt;- list()\ndlist2 &lt;- list()\nyrs &lt;- unique(airtemp$broodyr)\nsites &lt;- unique(airtemp$site)\nfor (j in 1:length(sites)) {\n  for (i in 1:length(yrs)) {\n    d &lt;- filter(airtemp, broodyr == yrs[i] & site == sites[j])\n    d$bydoy &lt;- c(1:dim(d)[1])\n    dlist1[[i]] &lt;- d\n  }\n  dlist2[[j]] &lt;- dlist1\n}\nairtemp2 &lt;- bind_rows(dlist2) %&gt;% filter(!is.na(tmean)) # bind and drop rows with NA\nairtemp2\n\n\n# A tibble: 42,519 × 12\n   station     site  date        tmin  tmax tmean tmean_int  year month  yday\n   &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 USC00486428 moose 1960-09-01   6.1  21.7  13.9      13.9  1960     9   245\n 2 USC00486428 moose 1960-09-02   7.8  25.6  16.7      16.7  1960     9   246\n 3 USC00486428 moose 1960-09-03   7.8  27.8  17.8      17.8  1960     9   247\n 4 USC00486428 moose 1960-09-04  10    25.6  17.8      17.8  1960     9   248\n 5 USC00486428 moose 1960-09-05   5    25.6  15.3      15.3  1960     9   249\n 6 USC00486428 moose 1960-09-06   4.4  25    14.7      14.7  1960     9   250\n 7 USC00486428 moose 1960-09-07   3.3  22.8  13.0      13.0  1960     9   251\n 8 USC00486428 moose 1960-09-08   2.2  21.7  12.0      12.0  1960     9   252\n 9 USC00486428 moose 1960-09-09   1.1  23.9  12.5      12.5  1960     9   253\n10 USC00486428 moose 1960-09-10   0    22.2  11.1      11.1  1960     9   254\n# ℹ 42,509 more rows\n# ℹ 2 more variables: broodyr &lt;dbl&gt;, bydoy &lt;int&gt;",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environmental Covariates</span>"
    ]
  },
  {
    "objectID": "FlowTemp_Covariates.html#summarize-covariates",
    "href": "FlowTemp_Covariates.html#summarize-covariates",
    "title": "2  Environmental Covariates",
    "section": "2.3 Summarize Covariates",
    "text": "2.3 Summarize Covariates\n\n2.3.1 Managed Flow\nPlot JLD releases with winter and summer periods marked\n\n\nCode\nflow3 %&gt;% #filter(broodyr &gt;= 2014) %&gt;% \n  ggplot() + geom_line(aes(x = bydoy, y = SnakeMoran)) + \n  geom_vline(xintercept = c(45,211), color = \"blue\") +   # winter = Oct 15 - March 31\n  geom_vline(xintercept = c(91,180), color = \"dodgerblue\") +   # winter = Dec 1 - Feb 28/29\n  geom_vline(xintercept = c(303,365), color = \"red\") +   # summer = July 1 - August 31\n  facet_wrap(~ broodyr) +\n  theme_bw() + theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\nSummarize JLD release covariates (managed components)\n\n\nCode\njldflow &lt;- flow3 %&gt;% group_by(broodyr) %&gt;% \n  summarise(jld_winmean = mean(ifelse(bydoy &gt;= 45 & bydoy &lt;= 211, SnakeMoran, NA), na.rm = TRUE), # winter mean flow\n            jld_winmean_log = mean(ifelse(bydoy &gt;= 45 & bydoy &lt;= 211, log(SnakeMoran), NA), na.rm = TRUE),\n            jld_winvar = sd(ifelse(bydoy &gt;= 45 & bydoy &lt;= 211, varJLD, NA), na.rm = TRUE), # winter flow variability\n            jld_sprmean = mean(ifelse(bydoy &gt;= 212 & bydoy &lt;= 302, SnakeMoran, NA), na.rm = TRUE), # spring mean flow\n            jld_sprmean_log = mean(ifelse(bydoy &gt;= 212 & bydoy &lt;= 302, log(SnakeMoran), NA), na.rm = TRUE),\n            jld_sprvar = sd(ifelse(bydoy &gt;= 212 & bydoy &lt;= 302, varJLD, NA), na.rm = TRUE), # spring flow variability\n            jld_summean = mean(ifelse(bydoy &gt;= 303 & bydoy &lt;= 365, SnakeMoran, NA), na.rm = TRUE), # summer mean flows\n            jld_summean_log = mean(ifelse(bydoy &gt;= 303 & bydoy &lt;= 365, log(SnakeMoran), NA), na.rm = TRUE),\n            jld_sumvar = sd(ifelse(bydoy &gt;= 303 & bydoy &lt;= 365, varJLD, NA), na.rm = TRUE), # summer variability\n            jld_peakmag = max(SnakeMoran, na.rm = TRUE), # magnitude of peak spring/summer flows\n            jld_peakmag_log = max(log(SnakeMoran), na.rm = TRUE),\n            jld_peaktime = ifelse(bydoy[which.max(SnakeMoran)] &gt; 200 & bydoy[which.max(SnakeMoran)] &lt; 325, bydoy[which.max(SnakeMoran)], NA), # timing of peak flows\n            # minimum flow - raw\n            jld_annmin = min((SnakeMoran), na.rm = TRUE), # annual minimum flow\n            jld_winmin = min(ifelse(bydoy &gt;= 45 & bydoy &lt;= 211, (SnakeMoran), NA), na.rm = TRUE), # winter minimum flow\n            jld_sprmin = min(ifelse(bydoy &gt;= 212 & bydoy &lt;= 302, (SnakeMoran), NA), na.rm = TRUE), # spring minimum flow\n            jld_summin = min(ifelse(bydoy &gt;= 303 & bydoy &lt;= 365, (SnakeMoran), NA), na.rm = TRUE), # summer minimum flow\n            # minimum flow - logged\n            jld_annmin_log = min(log(SnakeMoran), na.rm = TRUE), # annual minimum flow\n            jld_winmin_log = min(ifelse(bydoy &gt;= 45 & bydoy &lt;= 211, log(SnakeMoran), NA), na.rm = TRUE), # winter minimum flow\n            jld_sprmin_log = min(ifelse(bydoy &gt;= 212 & bydoy &lt;= 302, log(SnakeMoran), NA), na.rm = TRUE), # spring minimum flow\n            jld_summin_log = min(ifelse(bydoy &gt;= 303 & bydoy &lt;= 365, log(SnakeMoran), NA), na.rm = TRUE) # summer minimum flow\n  ) %&gt;% ungroup() \n\n\nPlot time series of managed flow covariate data:\n\n\nCode\npar(mfrow = c(4,3), mar = c(3,4,1,1))\nplot(jld_winmean ~ broodyr, jldflow, type = \"b\")\nplot(jld_winmean_log ~ broodyr, jldflow, type = \"b\")\nplot(jld_winvar ~ broodyr, jldflow, type = \"b\")\n\nplot(jld_sprmean ~ broodyr, jldflow, type = \"b\")\nplot(jld_sprmean_log ~ broodyr, jldflow, type = \"b\")\nplot(jld_sprvar ~ broodyr, jldflow, type = \"b\")\n\nplot(jld_summean ~ broodyr, jldflow, type = \"b\")\nplot(jld_summean_log ~ broodyr, jldflow, type = \"b\")\nplot(jld_sumvar ~ broodyr, jldflow, type = \"b\")\n\nplot(jld_peakmag ~ broodyr, jldflow, type = \"b\")\nplot(jld_peakmag_log ~ broodyr, jldflow, type = \"b\")\nplot(jld_peaktime ~ broodyr, jldflow, type = \"b\")\n\n\n\n\n\n\n\n\n\nAnnual and seasonal minimum flow. Horiztonal red line denotes 280 cfs. Vertical grey line denotes 1989.\n\n\nCode\npar(mfrow = c(2,2), mar = c(3,4,1,1))\nplot(jld_annmin ~ broodyr, jldflow, type = \"b\")\nabline(h = (280), col = \"red\", lty = 2)\nabline(v = (1989), col = \"black\", lty = 2)\nplot(jld_winmin ~ broodyr, jldflow, type = \"b\")\nabline(h = (280), col = \"red\", lty = 2)\nabline(v = (1989), col = \"black\", lty = 2)\nplot(jld_sprmin ~ broodyr, jldflow, type = \"b\")\nabline(h = (280), col = \"red\", lty = 2)\nabline(v = (1989), col = \"black\", lty = 2)\nplot(jld_summin ~ broodyr, jldflow, type = \"b\")\nabline(h = (280), col = \"red\", lty = 2)\nabline(v = (1989), col = \"black\", lty = 2)\n\n\n\n\n\n\n\n\n\nLog scale\n\n\nCode\npar(mfrow = c(2,2), mar = c(3,4,1,1))\nplot((jld_annmin_log) ~ broodyr, jldflow, type = \"b\")\nabline(h = log(280), col = \"red\", lty = 2)\nplot((jld_winmin_log) ~ broodyr, jldflow, type = \"b\")\nabline(h = log(280), col = \"red\", lty = 2)\nplot((jld_sprmin_log) ~ broodyr, jldflow, type = \"b\")\nabline(h = log(280), col = \"red\", lty = 2)\nplot((jld_summin_log) ~ broodyr, jldflow, type = \"b\")\nabline(h = log(280), col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\nPairs plots for key managed flow covariates:\n\n\nCode\nggpairs(jldflow %&gt;% select(broodyr, jld_summean, jld_peakmag, jld_peaktime, jld_winmean, jld_winvar))\n\n\n\n\n\n\n\n\n\n\n2.3.1.1 Ramp-down\nLoad manually identified autumn ramp-down covariate data:\n\n\nCode\njldramp &lt;- read_csv(\"Data/Derived/JLD_RampDown_Summary_CalendarYear_1960-2022.csv\") \n\n\nPairs plot of key variables:\n\n\nCode\nggpairs(jldramp %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin, jld_rampratemin_log))\n\n\n\n\n\n\n\n\n\nPlot time series of key ramping variables\n\n\nCode\npar(mfrow = c(1,3), mgp = c(2.5, 1.25, 0), mar = c(4,4,1,1))\n\nplot(jld_winvar ~ broodyr, jldflow, type = \"l\", bty = \"l\", xlab = \"Year\", ylab = \"JLD winter flow variability\")\npoints(jld_winvar ~ broodyr, jldflow, pch = 16)\nabline(v = 1989, col = \"red\", lty = 2)\nabline(v = 1996, col = \"grey50\", lty = 2)\n\nplot(jld_rampdur ~ broodyr, jldramp, type = \"l\", bty = \"l\", xlab = \"Year\", ylab = \"Duration of ramp-down (days)\")\npoints(jld_rampdur ~ broodyr, jldramp, pch = 16)\nabline(v = 1989, col = \"red\", lty = 2)\nabline(v = 1996, col = \"grey50\", lty = 2)\n\nplot(jld_rampratemindoy ~ broodyr, jldramp, type = \"l\", bty = \"l\", xlab = \"Year\", ylab = \"Timing of ramp-down (julian date)\")\npoints(jld_rampratemindoy ~ broodyr, jldramp, pch = 16)\nabline(v = 1989, col = \"red\", lty = 2)\nabline(v = 1996, col = \"grey50\", lty = 2)\n\n\n\n\n\n\n\n\n\nWrite out managed flow data file:\n\n\nCode\nwrite_csv(jldflow, \"Data/Derived/JLD_ManagedFlow_Covariates_BroodYear_1960-2022.csv\")\n\n\n\n\n\n2.3.2 Natural Flow\nView time series data by stream and year, with seasons marked\n\n\nCode\nflow6 %&gt;%\n  filter(site == \"SnakeNat\", broodyr &gt;= 1975) %&gt;%\n  ggplot() + \n  geom_line(aes(x = bydoy, y = flow_cfs)) + \n  geom_vline(xintercept =c(1,90), color = \"green\") +   # fall = Sept 1 - Nov 30\n  geom_vline(xintercept = c(91,181), color = \"blue\") +   # winter = Dec 1 - Feb 29\n  geom_vline(xintercept = c(182,274), color = \"orange\") +   # spring = March 1 - May 31\n  geom_vline(xintercept = c(275,365), color = \"red\") +   # summer = June 1 - Aug 31\n  facet_wrap(~ broodyr) + theme_bw() + theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\nCalculate flow metrics for each sites\n\n\nCode\n# define season and cutoff for data completeness (70%)\nflow6 &lt;- flow6 %&gt;% mutate(season = ifelse(bydoy &gt;= 1 & bydoy &lt;= 90, \"fal\",\n                                          ifelse(bydoy &gt;= 91 & bydoy &lt;= 181, \"win\",\n                                                 ifelse(bydoy &gt;= 182 & bydoy &lt;= 274, \"spr\", \"sum\"))),\n                          cutoff = ifelse(season == \"fal\", 63, \n                                          ifelse(season == \"win\", 63,\n                                                 ifelse(season == \"spr\", 63, 63))))\nflow6 &lt;- flow6 %&gt;% left_join(flow6 %&gt;% group_by(site, broodyr, season) %&gt;% summarise(n = sum(!is.na(flow_cfs))))\n\n# define seasons for loop\nsns &lt;- unique(flow6$season)\n\n# seasonal mean flow\nflowlist &lt;- list()\nfor (i in 1:length(sns)) {\n  d &lt;- flow6 %&gt;% filter(season == sns[i])\n  d &lt;- d[complete.cases(d),]\n  flowlist[[i]] &lt;- d %&gt;% \n    group_by(site, season, broodyr, cutoff, n) %&gt;% \n    summarize(flowmean = ifelse(unique(n) &lt;= unique(cutoff), NA, mean(flow_cfs, na.rm = TRUE))) %&gt;% ungroup() %&gt;%\n    select(site, season, broodyr, flowmean) \n}\nflowsum1 &lt;- bind_rows(flowlist) %&gt;% spread(season, flowmean) %&gt;% rename(natq_falmean = fal, natq_winmean = win, natq_sprmean = spr, natq_summean = sum)\n\n# seasonal log flow \nflowlist &lt;- list()\nfor (i in 1:length(sns)) {\n  d &lt;- flow6 %&gt;% filter(season == sns[i])\n  d &lt;- d[complete.cases(d),]\n  flowlist[[i]] &lt;- d %&gt;% \n    group_by(site, season, broodyr, cutoff, n) %&gt;% \n    summarize(flowmean_log = ifelse(unique(n) &lt;= unique(cutoff), NA, mean(log(flow_cfs), na.rm = TRUE))) %&gt;% ungroup() %&gt;%\n    select(site, season, broodyr, flowmean_log) \n}\nflowsum2 &lt;- bind_rows(flowlist) %&gt;% spread(season, flowmean_log) %&gt;% rename(natq_falmean_log = fal, natq_winmean_log = win, natq_sprmean_log = spr, natq_summean_log = sum)\n\n# seasonal flow variation\nflowlist &lt;- list()\nfor (i in 1:length(sns)) {\n  d &lt;- flow6 %&gt;% filter(season == sns[i])\n  d &lt;- d[complete.cases(d),]\n  flowlist[[i]] &lt;- d %&gt;% \n    group_by(site, season, broodyr, cutoff, n) %&gt;% \n    summarize(flowvar = ifelse(unique(n) &lt;= unique(cutoff), NA, sd(flow_var, na.rm = TRUE))) %&gt;% ungroup() %&gt;%\n    select(site, season, broodyr, flowvar) \n}\nflowsum3 &lt;- bind_rows(flowlist) %&gt;% spread(season, flowvar) %&gt;% rename(natq_falvar = fal, natq_winvar = win, natq_sprvar = spr, natq_sumvar = sum)\n\n# annual flow metrics (no data availability cutoff)\nflowlist &lt;- list()\nsites &lt;- unique(flow6$site)\nfor (i in 1:length(sites)) {\n  d &lt;- flow6 %&gt;% filter(site == sites[i])\n  d &lt;- d[complete.cases(d),]\n  flowlist[[i]] &lt;- d %&gt;% group_by(site, broodyr) %&gt;% \n    summarize(natq_peakmag = max(flow_cfs, na.rm = TRUE), # magnitude of peak spring flows\n              natq_peakmag_log = max(log(flow_cfs), na.rm = TRUE), # logged\n              natq_annmin = min(flow_cfs, na.rm = TRUE), # annual minimum flow\n              natq_annmin_log = min(log(flow_cfs), na.rm = TRUE), # logged\n              natq_peaktime = bydoy[which.max(flow_cfs)], # brood year day of peak spring flows\n              natq_flooddur = sum(flow_cfs &gt;= quantile(d$flow_cfs[!is.na(d$flow_cfs)], probs = 0.75), na.rm = T), # number of days flow is greater than the long-term 75th percentile of flow\n              natq_floodvar = sd(flow_var[flow_cfs &gt;= quantile(d$flow_cfs[!is.na(d$flow_cfs)], probs = 0.75)], na.rm = TRUE), # spring/summer flood variability (var in flood pulse)\n              natq_floodmag = sum(flow_cfs[flow_cfs &gt;= quantile(d$flow_cfs[!is.na(d$flow_cfs)], probs = 0.75)], na.rm = T) # magnitude of spring flood (flow &gt; long-term 75th percentile)\n    ) %&gt;% ungroup()\n}\nflowsum4 &lt;- bind_rows(flowlist) \n\n# join\nflowsum &lt;- flowsum1 %&gt;% left_join(flowsum2) %&gt;% left_join(flowsum3) %&gt;% left_join(flowsum4)\n\n\nPlot time series data (natural Snake River only)\n\n\nCode\n  d &lt;- flowsum %&gt;% filter(site == \"SnakeNat\")\n  par(mfrow = c(7,3), mar = c(3,4,1,1))\n  \n  plot(natq_falmean ~ broodyr, d, type = \"b\")\n  plot(natq_falmean_log ~ broodyr, d, type = \"b\")\n  plot(natq_falvar ~ broodyr, d, type = \"b\")\n  \n  plot(natq_winmean ~ broodyr, d, type = \"b\")\n  plot(natq_winmean_log ~ broodyr, d, type = \"b\")\n  plot(natq_winvar ~ broodyr, d, type = \"b\")\n  \n  plot(natq_sprmean ~ broodyr, d, type = \"b\")\n  plot(natq_sprmean_log ~ broodyr, d, type = \"b\")\n  plot(natq_sprvar ~ broodyr, d, type = \"b\")\n  \n  plot(natq_summean ~ broodyr, d, type = \"b\")\n  plot(natq_summean_log ~ broodyr, d, type = \"b\")\n  plot(natq_sumvar ~ broodyr, d, type = \"b\")\n  \n  plot(natq_peakmag ~ broodyr, d, type = \"b\")\n  plot(natq_peakmag_log ~ broodyr, d, type = \"b\")\n  plot(natq_peaktime ~ broodyr, d, type = \"b\")\n  \n  plot(natq_flooddur ~ broodyr, d, type = \"b\")\n  plot(natq_floodvar ~ broodyr, d, type = \"b\")\n  plot(natq_floodmag ~ broodyr, d, type = \"b\")\n  \n  plot(natq_annmin ~ broodyr, d, type = \"b\")\n  plot(natq_annmin_log ~ broodyr, d, type = \"b\")\n\n\n\n\n\n\n\n\n\nWrite out data file\n\n\nCode\nwrite_csv(flowsum, \"Data/Derived/SnakeTribs_NaturalFlow_Covariates_BroodYear_1960-2022.csv\")\nflowsum &lt;- read_csv(\"Data/Derived/SnakeTribs_NaturalFlow_Covariates_BroodYear_1960-2022.csv\")\n\n\nHow many/what proportion of years since 1989 have combined winter flows been below certain thresholds? e.g., 1302 cfs and winter mean flow\n\n\nCode\nflowsum %&gt;% filter(site == \"SnakeBeFlat\") %&gt;% \n  ggplot(aes(x = broodyr, y = natq_winmean)) + geom_line() + geom_point() + geom_hline(yintercept = 1302, color = \"red\")\n\n\n\n\n\n\n\n\n\nCode\ndim(flowsum %&gt;% filter(site == \"SnakeBeFlat\", broodyr &gt;= 1989, natq_winmean &gt;= 1302))[1] / dim(flowsum %&gt;% filter(site == \"SnakeBeFlat\", broodyr &gt;= 1989))[1]\n\n\n[1] 0.4705882\n\n\nHistorical (1989-present) seasonal flow summaries for Bryana (25, 50, and 75% quantiles)\n\n\nCode\nbry_flowsum &lt;- flowsum %&gt;% filter(broodyr &gt;= 1989, site %in% c(\"SnakeBeFlat\", \"SnakeMoran\", \"SnakeNat\")) %&gt;% group_by(site) %&gt;%\n  reframe(q_fal_25 = quantile(natq_falmean, probs = 0.25, na.rm = T), q_fal_50 = quantile(natq_falmean, probs = 0.50, na.rm = T), q_fal_75 = quantile(natq_falmean, probs = 0.75, na.rm = T),\n          q_win_25 = quantile(natq_winmean, probs = 0.25, na.rm = T), q_win_50 = quantile(natq_winmean, probs = 0.50, na.rm = T), q_win_75 = quantile(natq_winmean, probs = 0.75, na.rm = T),\n          q_spr_25 = quantile(natq_sprmean, probs = 0.25, na.rm = T), q_spr_50 = quantile(natq_sprmean, probs = 0.50, na.rm = T), q_spr_75 = quantile(natq_sprmean, probs = 0.75, na.rm = T),\n          q_sum_25 = quantile(natq_summean, probs = 0.25, na.rm = T), q_sum_50 = quantile(natq_summean, probs = 0.50, na.rm = T), q_sum_75 = quantile(natq_summean, probs = 0.75, na.rm = T),\n          q_peakmag_25 = quantile(natq_peakmag, probs = 0.25, na.rm = T), q_peakmag_50 = quantile(natq_peakmag, probs = 0.50, na.rm = T), q_peakmag_75 = quantile(natq_peakmag, probs = 0.75, na.rm = T),\n          q_peaktime_25 = quantile(natq_peaktime, probs = 0.25, na.rm = T), q_peaktime_50 = quantile(natq_peaktime, probs = 0.50, na.rm = T), q_peaktime_75 = quantile(natq_peaktime, probs = 0.75, na.rm = T)) %&gt;% \n  ungroup()\nwrite_csv(bry_flowsum, \"Data/Derived/Snake_FlowSummaryForBryana_1989-2022.csv\")\n\n# plot seasonal summaries\njpeg(\"Figures/Covariates/Snake_FlowSummaryForBryana_1989-2022.jpg\", units = \"in\", height = 10, width = 10, res = 500)\np1 &lt;- tibble(ssn = as.ordered(c(\"fal\", \"win\", \"spr\", \"sum\")), \n       q25 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeBeFlat\") %&gt;% select(q_fal_25, q_win_25, q_spr_25, q_sum_25)), \n       q50 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeBeFlat\") %&gt;% select(q_fal_50, q_win_50, q_spr_50, q_sum_50)), \n       q75 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeBeFlat\") %&gt;% select(q_fal_75, q_win_75, q_spr_75, q_sum_75))) %&gt;%\n  gather(quant, flow, q25:q75) %&gt;%\n  arrange(rev(quant)) %&gt;%\n  ggplot(aes(fill = quant, x = ssn, y = flow)) + geom_bar(position = \"identity\", stat = \"identity\") + scale_x_discrete(limits = c(\"fal\", \"win\", \"spr\", \"sum\")) + scale_y_continuous(limits = c(0,8100)) + theme(plot.margin = margin(1,0.5,0.5,0.5, unit = \"cm\"))\np2 &lt;- tibble(ssn = c(\"fal\", \"win\", \"spr\", \"sum\"), \n             q25 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeMoran\") %&gt;% select(q_fal_25, q_win_25, q_spr_25, q_sum_25)), \n             q50 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeMoran\") %&gt;% select(q_fal_50, q_win_50, q_spr_50, q_sum_50)), \n             q75 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeMoran\") %&gt;% select(q_fal_75, q_win_75, q_spr_75, q_sum_75))) %&gt;%\n  gather(quant, flow, q25:q75) %&gt;%\n  arrange(ssn, rev(quant)) %&gt;%\n  ggplot(aes(fill = quant, x = ssn, y = flow)) + geom_bar(position = \"identity\", stat = \"identity\") + scale_x_discrete(limits = c(\"fal\", \"win\", \"spr\", \"sum\")) + scale_y_continuous(limits = c(0,8100)) + theme(plot.margin = margin(1,0.5,0.5,0.5, unit = \"cm\"))\np3 &lt;- tibble(ssn = c(\"fal\", \"win\", \"spr\", \"sum\"), \n             q25 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeNat\") %&gt;% select(q_fal_25, q_win_25, q_spr_25, q_sum_25)), \n             q50 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeNat\") %&gt;% select(q_fal_50, q_win_50, q_spr_50, q_sum_50)), \n             q75 = unlist(bry_flowsum %&gt;% filter(site == \"SnakeNat\") %&gt;% select(q_fal_75, q_win_75, q_spr_75, q_sum_75))) %&gt;%\n  gather(quant, flow, q25:q75) %&gt;%\n  arrange(ssn, rev(quant)) %&gt;%\n  ggplot(aes(fill = quant, x = ssn, y = flow)) + geom_bar(position = \"identity\", stat = \"identity\") + scale_x_discrete(limits = c(\"fal\", \"win\", \"spr\", \"sum\")) + scale_y_continuous(limits = c(0,8100)) + theme(plot.margin = margin(1,0.5,0.5,0.5, unit = \"cm\"))\nggarrange(p1, p2, p3, labels = c(\"Snake Below Flat (combined)\", \"Snake Moran (JLD Release)\", \"Snake Natural (tributaries)\"))\ndev.off()\n\n\npng \n  2 \n\n\n\n\n2.3.3 Air Temperature\nPlot Moose, WY, air temp with seasons marked:\n\n\nCode\nairtemp2 %&gt;%\n  filter(site == \"moose\") %&gt;%\n  ggplot() + \n  geom_line(aes(x = bydoy, y = tmean)) + \n  geom_vline(xintercept = c(1,90), color = \"green\") +   # fall = Sept 1 - Nov 30\n  geom_vline(xintercept = c(91,181), color = \"blue\") +   # winter = Dec 1 - Feb 29\n  geom_vline(xintercept = c(182,274), color = \"orange\") +   # spring = March 1 - May 31\n  geom_vline(xintercept = c(275,365), color = \"red\") +   # summer = June 1 - Aug 31\n  facet_wrap(~ broodyr) +   # summer = June 1 - Aug 31\n  facet_wrap(~ broodyr) + theme_bw() + theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\nCalculate air temp. metrics for each site:\n\n\nCode\n# define season and cutoff for data completeness (70%)\nairtemp2a &lt;- airtemp2 %&gt;% mutate(season = ifelse(bydoy &gt;= 1 & bydoy &lt;= 90, \"fal\",\n                                                ifelse(bydoy &gt;= 91 & bydoy &lt;= 181, \"win\",\n                                                       ifelse(bydoy &gt;= 182 & bydoy &lt;= 274, \"spr\", \"sum\")))) %&gt;%\n                         mutate(cutoff = ifelse(season == \"fal\", 63, \n                                                ifelse(season == \"win\", 63,\n                                                       ifelse(season == \"spr\", 63, 63))))\nairtemp2 &lt;- airtemp2a %&gt;% left_join(airtemp2a %&gt;% group_by(site, broodyr, season) %&gt;% summarise(n = sum(!is.na(tmean))))\n\n# seasonal mean air temp \nairlist &lt;- list()\nsns &lt;- unique(airtemp2$season)\nfor (i in 1:length(sns)) {\n  d &lt;- airtemp2 %&gt;% filter(season == sns[i])\n  d &lt;- d[complete.cases(d),]\n  airlist[[i]] &lt;- d %&gt;% \n    group_by(site, season, broodyr, cutoff, n) %&gt;% \n    summarize(tmean = ifelse(unique(n) &lt;= unique(cutoff), NA, mean(tmean, na.rm = TRUE)),\n              tmax = ifelse(unique(n) &lt;= unique(cutoff), NA, mean(tmax, na.rm = TRUE)),\n              tmin = ifelse(unique(n) &lt;= unique(cutoff), NA, mean(tmin, na.rm = TRUE))) %&gt;% ungroup() %&gt;%\n    select(site, season, broodyr, tmean, tmax, tmin) \n}\nairsum1a &lt;- bind_rows(airlist) %&gt;% select(-c(tmax, tmin)) %&gt;% spread(season, tmean) %&gt;% rename(temp_falmean = fal, temp_winmean = win, temp_sprmean = spr, temp_summean = sum) \nairsum1b &lt;- bind_rows(airlist) %&gt;% select(-c(tmean, tmin))  %&gt;% spread(season, tmax) %&gt;% rename(temp_falmax = fal, temp_winmax = win, temp_sprmax = spr, temp_summax = sum)\nairsum1c &lt;- bind_rows(airlist) %&gt;% select(-c(tmax, tmean))  %&gt;% spread(season, tmin) %&gt;% rename(temp_falmin = fal, temp_winmin = win, temp_sprmin = spr, temp_summin = sum) \nairsum1 &lt;- airsum1a %&gt;% left_join(airsum1b) %&gt;% left_join(airsum1c)\n\n# annual temp metrics\nairlist &lt;- list()\nsites &lt;- unique(airtemp2$site)\nairsum3 &lt;- airtemp2 %&gt;% select(-n) %&gt;%\n  left_join(airtemp2 %&gt;% group_by(site, broodyr) %&gt;% summarise(n = sum(!is.na(tmean)))) \nfor (i in 1:length(sites)) {\n  d &lt;- airsum3 %&gt;% filter(site == sites[i])\n  d &lt;- d[complete.cases(d),]\n  airlist[[i]] &lt;- d %&gt;% group_by(site, broodyr, n) %&gt;% \n    summarize(temp_bel0dur = ifelse(unique(n) &lt;= 255, NA, sum(tmean &lt;= 0, na.rm = TRUE)),\n              temp_abv15dur = ifelse(unique(n) &lt;= 255, NA, sum(tmean &gt;= 15, na.rm = TRUE)),\n              temp_abv18dur = ifelse(unique(n) &lt;= 255, NA, sum(tmean &gt;= 18, na.rm = TRUE)),\n              temp_abv20dur = ifelse(unique(n) &lt;= 255, NA, sum(tmean &gt;= 20, na.rm = TRUE)),\n              temp_annmin = ifelse(unique(n) &lt;= 255, NA, min(tmean, na.rm = TRUE)),\n              temp_annmax = ifelse(unique(n) &lt;= 255, NA, max(tmean, na.rm = TRUE))\n              ) %&gt;% ungroup()\n}\nairsum2 &lt;- bind_rows(airlist) %&gt;% select(-n)\n\n# join\nairsum &lt;- airsum1 %&gt;% left_join(airsum2)\n\n\nTime series plots, Moose only\n\n\nCode\n  d &lt;- airsum %&gt;% filter(site == \"moose\")\n  par(mfrow = c(4,3), mar = c(3,4,1,1))\n  \n  plot(temp_falmean ~ broodyr, d, type = \"b\")\n  legend(\"bottomright\", legend = sites[i], bty = \"n\")\n  plot(temp_falmin ~ broodyr, d, type = \"b\")\n  plot(temp_falmax ~ broodyr, d, type = \"b\")\n  \n  plot(temp_winmean ~ broodyr, d, type = \"b\")\n  plot(temp_winmin ~ broodyr, d, type = \"b\")\n  plot(temp_winmax ~ broodyr, d, type = \"b\")\n  \n  plot(temp_sprmean ~ broodyr, d, type = \"b\")\n  plot(temp_sprmin ~ broodyr, d, type = \"b\")\n  plot(temp_sprmax ~ broodyr, d, type = \"b\")\n  \n  plot(temp_summean ~ broodyr, d, type = \"b\")\n  plot(temp_summin ~ broodyr, d, type = \"b\")\n  plot(temp_summax ~ broodyr, d, type = \"b\")\n\n\n\n\n\n\n\n\n\nCompare summer mean and min temps per Bryan Shuman comment\n\n\nCode\n# jpeg(\"Redd Counts Ricker/SummerTempCovs.jpg\", units = \"in\", height = 6, width = 8, res = 500)\np1 &lt;- airsum %&gt;% filter(site == \"moose\") %&gt;% ggplot(aes(x = broodyr, y = temp_summean)) + geom_point() + geom_line() + xlab(\"Brood Year\") + ylab(\"Summer mean temperature\") + theme(plot.margin = margin(0.5,0.5,0.5,0.5, unit = \"cm\"))\np2 &lt;- airsum %&gt;% filter(site == \"moose\") %&gt;% ggplot(aes(x = broodyr, y = temp_summin)) + geom_point() + geom_line() + xlab(\"Brood Year\") + ylab(\"Summer minimum temperature\") + theme(plot.margin = margin(0.5,0.5,0.5,0.5, unit = \"cm\"))\np3 &lt;- airsum %&gt;% filter(site == \"moose\") %&gt;% ggplot(aes(x = temp_summean, y = temp_summin)) + geom_point() + xlab(\"Mean\") + ylab(\"Minimum\") + stat_cor(method = \"pearson\") + theme(plot.margin = margin(0.5,0.5,0.5,0.5, unit = \"cm\"))\nggarrange(ggarrange(p1, p2, nrow = 2), p3, ncol = 2)\n\n\n\n\n\n\n\n\n\nCode\n# dev.off()\n\n\nPlot time series of temperature thresholds:\n\n\nCode\n  d &lt;- airsum %&gt;% filter(site == \"moose\")\n  par(mfrow = c(3,2), mar = c(3,4,1,1))\n  plot(temp_bel0dur ~ broodyr, d, type = \"b\")\n  plot(temp_abv15dur ~ broodyr, d, type = \"b\")\n  plot(temp_abv18dur ~ broodyr, d, type = \"b\")\n  plot(temp_abv20dur ~ broodyr, d, type = \"b\")\n  plot(temp_annmin ~ broodyr, d, type = \"b\")\n  plot(temp_annmax ~ broodyr, d, type = \"b\")\n\n\n\n\n\n\n\n\n\nPairs plots of seasonal mean air temperature variables:\n\n\nCode\nggpairs(airsum %&gt;% select(temp_falmean, temp_winmean, temp_sprmean, temp_summean))\n\n\n\n\n\n\n\n\n\nWrite out data file\n\n\nCode\nwrite_csv(airsum, \"Data/Derived/AirTemperature_Covariates_BroodYear_1960-2022.csv\")\nairsum &lt;- read_csv(\"Data/Derived/AirTemperature_Covariates_BroodYear_1960-2022.csv\")\n\n\nPlot select air temperature time series data:\n\n\nCode\njpeg(\"Figures/Covariates/SelectAirTempCovs.jpg\", units = \"in\", width = 7, height = 3.5, res = 1000)\npar(mfrow = c(1,2), mgp = c(2.5, 1, 0), mar = c(4,4,1,1))\n\n# fall\n# plot(temp_falmean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), type = \"l\", bty = \"l\", xlab = \"Year\", ylab = expression(paste(\"Fall temperature (\"^\"o\", \"C)\", sep = \"\")))\n# points(temp_falmean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), pch = 16)\n# mod &lt;- lm(temp_falmean ~ broodyr, airsum %&gt;% filter(site == \"moose\" & broodyr &gt;= 1980))\n# predz &lt;- predict(mod, newdata = list(broodyr = c(1980:2022)))\n# lines(predz ~ c(1980:2022), lwd = 2, col = \"red\")\n\n# winter\nplot(temp_winmean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), type = \"l\", bty = \"l\", xlab = \"Year\", ylab = expression(paste(\"Winter temperature (\"^\"o\", \"C)\", sep = \"\")))\npoints(temp_winmean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), pch = 16)\nmod &lt;- lm(temp_winmean ~ broodyr, airsum %&gt;% filter(site == \"moose\" & broodyr &gt;= 1980))\npredz &lt;- predict(mod, newdata = list(broodyr = c(1980:2022)))\nlines(predz ~ c(1980:2022), lwd = 2, col = \"red\")\n\n# spring\n# plot(temp_sprmean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), type = \"l\", bty = \"l\", xlab = \"Year\", ylab = expression(paste(\"Spring temperature (\"^\"o\", \"C)\", sep = \"\")))\n# points(temp_sprmean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), pch = 16)\n# mod &lt;- lm(temp_sprmean ~ broodyr, airsum %&gt;% filter(site == \"moose\" & broodyr &gt;= 1980))\n# predz &lt;- predict(mod, newdata = list(broodyr = c(1980:2022)))\n# lines(predz ~ c(1980:2022), lwd = 2, col = \"red\")\n\n# summer\nplot(temp_summean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), type = \"l\", bty = \"l\", xlab = \"Year\", ylab = expression(paste(\"Summer temperature (\"^\"o\", \"C)\", sep = \"\")))\npoints(temp_summean ~ broodyr, airsum %&gt;% filter(site == \"moose\"), pch = 16)\nmod &lt;- lm(temp_summean ~ broodyr, airsum %&gt;% filter(site == \"moose\" & broodyr &gt;= 1980))\npredz &lt;- predict(mod, newdata = list(broodyr = c(1980:2022)))\nlines(predz ~ c(1980:2022), lwd = 2, col = \"red\")\n\ndev.off()\n\n\npng \n  2",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environmental Covariates</span>"
    ]
  },
  {
    "objectID": "JoinFishDataWithCovariates.html",
    "href": "JoinFishDataWithCovariates.html",
    "title": "3  Join Fish and Env. Data",
    "section": "",
    "text": "3.1 Redd Count Data\nPurpose: join redd count and environmental covariate data and explore correlations between key environmental variables.\nLoad YCT redd count data and plot time series\nCode\nredds &lt;- read_csv(\"Data/ReddCounts_WGFD_1971-2021_cleaned.csv\") %&gt;% \n  filter(!stream %in% c(\"Cody\", \"Christiansen\", \"Dave\", \"Laker\")) # drop Cody (too few data points) and Salt River tribs\nredds %&gt;% ggplot() + geom_point(aes(x = year, y = reddspermile)) + geom_line(aes(x = year, y = reddspermile)) + facet_wrap(~ stream, scales = \"free_y\") + theme_bw() + theme(panel.grid = element_blank())\nMap sites:\nCode\nreddlocs &lt;- redds %&gt;% group_by(stream) %&gt;% summarize(lat = unique(lat), long = unique(long)) # summarize location data\nreddlocs_sp &lt;- st_as_sf(reddlocs, coords = c(\"long\", \"lat\"), crs = \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84\")\n# st_write(reddlocs_sp, \"Redd Counts Ricker/Spatial/ReddCounts_SpatialLocations.shp\", append = FALSE)\nmapview(reddlocs_sp) # map\nExplore autocorrelation, which may be due to stock-recruit dynamics, autocorrelated environmental drivers, or both\nCode\nsites &lt;- unique(redds$stream)\npar(mfrow = c(4,4), mgp = c(2.5,1,0), mar = c(3.5,3.5,1,1))\nfor (i in 1:length(sites)) {\n  d &lt;- filter(redds, stream == sites[i])\n  acf(d$reddsperkm, lag.max = 6, plot = TRUE, na.action = na.pass)\n  legend(\"topright\", legend = sites[i], bty = \"n\")\n}\nFor each site, add years in which data was not collected, then calculate lagged redds\nCode\nlagg &lt;- 4\nrlist &lt;- list()\nsites &lt;- unique(redds$stream)\nfor (i in 1:length(sites)) {\n  d &lt;- filter(redds, stream == sites[i])\n  df1 &lt;- tibble(year = seq(from = min(d$year, na.rm = TRUE), to = max(d$year, na.rm = T), by = 1))\n  rlist[[i]] &lt;- df1 %&gt;% left_join(d) %&gt;% mutate(stream = sites[i], \n                                                miles = unique(d$miles), \n                                                kms = unique(d$kms), \n                                                lat = unique(d$lat), \n                                                long = unique(d$long),\n                                                reddsperkm_lag4 = lag(reddsperkm, n = lagg))\n}\nredds2 &lt;- bind_rows(rlist)\nExplore the effect of spawners on productivity to motivate use of Ricker model, sensu Jones et al. (2020).\nCode\n# recruits ~ spawners, combined\n# redds2 %&gt;% ggplot(aes(x = reddsperkm_lag4, y = reddsperkm)) +\n#   geom_point(aes(colour = stream)) +\n#   geom_smooth(method = \"loess\")\n# recruits ~ spawners, by stream\n# redds2 %&gt;% ggplot(aes(x = reddsperkm_lag4, y = reddsperkm)) + \n#   geom_point(aes(colour = year)) + \n#   geom_smooth() +\n#   facet_wrap(~stream, scales = \"free\")\n# # productivity ~ time, by stream\n# redds2 %&gt;% ggplot(aes(x = year, y = log(reddsperkm/reddsperkm_lag4))) + \n#   geom_point(aes(colour = year)) + \n#   geom_smooth() +\n#   facet_wrap(~stream, scales = \"free_y\")\n# productivity ~ spawning stock, combined\n# redds2 %&gt;% ggplot(aes(x = reddsperkm_lag4, y = log(reddsperkm/reddsperkm_lag4))) + \n#   geom_smooth(method = \"lm\") +\n#   geom_point(aes(colour = stream))\n# productivity ~ spawning stock, by stream\nredds2 %&gt;% ggplot(aes(x = reddsperkm_lag4, y = log(reddsperkm/reddsperkm_lag4), colour = year)) + \n  geom_smooth(method = \"lm\") +\n  geom_point(aes(colour = year)) + \n  facet_wrap(~stream, scales = \"free\")\nGet range of years by site\nCode\nredds2 %&gt;% group_by(stream) %&gt;% summarize(start = min(year, na.rm = TRUE), stop = max(year, na.rm = TRUE))\n\n\n# A tibble: 13 × 3\n   stream                   start  stop\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;\n 1 3 Channel                 1973  2014\n 2 Blacktail                 1973  2016\n 3 Blue Crane                1985  2015\n 4 Cowboy Cabin              1980  2016\n 5 Fish                      1984  2016\n 6 Flat                      1976  2015\n 7 Little Bar BC             1978  2016\n 8 Lower Bar BC              1971  2021\n 9 Nowlin                    1976  2015\n10 Price                     1975  2006\n11 Snake River Side Channel  1986  2002\n12 Spring                    1988  2007\n13 Upper Bar BC              1974  2016\n\n\nCode\nminby &lt;- min(redds2$year) - 4 # minimum brood year",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Join Fish and Env. Data</span>"
    ]
  },
  {
    "objectID": "JoinFishDataWithCovariates.html#covariate-data",
    "href": "JoinFishDataWithCovariates.html#covariate-data",
    "title": "3  Join Fish and Env. Data",
    "section": "3.2 Covariate Data",
    "text": "3.2 Covariate Data\nPer Murdoch et al (2023) CJFAS, only include variables for which Pearson’s r is &lt; 0.6.\nNotes: * drop jld_winmean and natq_winmean from same model (pearson r = 0.639 since 1960, 0.79 since 1989)\nLoad derived data files\n\n\nCode\njldramp &lt;- read_csv(\"Data/Derived/JLD_RampDown_Summary_CalendarYear_1960-2022.csv\") #%&gt;% mutate(broodyr = year) %&gt;% select(-year)\njldflow &lt;- read_csv(\"Data/Derived/JLD_ManagedFlow_Covariates_BroodYear_1960-2022.csv\")\nnatflow &lt;- read_csv(\"Data/Derived/SnakeTribs_NaturalFlow_Covariates_BroodYear_1960-2022.csv\") %&gt;% rename(flowstn = site) #%&gt;% filter(site %in% c(\"SnakeBeFlat\", \"Salt\")) \nairtemp &lt;- read_csv(\"Data/Derived/AirTemperature_Covariates_BroodYear_1960-2022.csv\") %&gt;% filter(site %in% c(\"moose\", \"afton\")) %&gt;% rename(tempstn = site) \n\nunique(natflow$flowstn)\n\n\n[1] \"Buffalo\"     \"Fish\"        \"Flat\"        \"Greys\"       \"GrosVentre\" \n[6] \"Salt\"        \"SnakeBeFlat\" \"SnakeMoran\"  \"SnakeNat\"   \n\n\n\n3.2.1 Check correlation\nUse pairs plots to check correlation among key variables, within datasets:\n\nRamp-down: completeRamp-down: post-1989JLD flow: completeJLD flow: post-1989Nat. flow: completeNat. flow: post-1989Comb. flow: completeComb. flow: post-1989Temp: completeTemp: post-1989\n\n\n\n\nCode\nggpairs(jldramp %&gt;% select(jld_rampdur, jld_rampratemindoy, jld_rampratemin_log), progress = FALSE ) # entire time series\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(jldramp %&gt;% filter(broodyr &gt;= 1989) %&gt;% select(jld_rampdur, jld_rampratemindoy, jld_rampratemin_log) , progress = FALSE) # post-1989\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(jldflow %&gt;% select(jld_winmean, jld_winmin, jld_winvar, jld_summean, jld_peakmag, jld_peaktime), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(jldflow %&gt;% filter(broodyr &gt;= 1989) %&gt;% select(jld_winmean, jld_winvar, jld_summean, jld_peakmag, jld_peaktime), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(natq_annmin, natq_winmean, natq_winvar, natq_peakmag, natq_peaktime), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(natflow %&gt;% filter(broodyr &gt;= 1989, flowstn == \"SnakeNat\") %&gt;% select(natq_winmean, natq_winvar, natq_peakmag, natq_peaktime), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(natflow %&gt;% filter(flowstn == \"SnakeBeFlat\") %&gt;% select(natq_winmean, natq_winvar, natq_peakmag, natq_peaktime), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(natflow %&gt;% filter(broodyr &gt;= 1989, flowstn == \"SnakeBeFlat\") %&gt;% select(natq_winmean, natq_winvar, natq_peakmag, natq_peaktime), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(airtemp %&gt;% filter(tempstn == \"moose\") %&gt;% select(temp_falmean, temp_winmean, temp_sprmean, temp_summean), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggpairs(airtemp %&gt;% filter(broodyr &gt;= 1989, tempstn == \"moose\") %&gt;% select(temp_falmean, temp_winmean, temp_sprmean, temp_summean), progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nCheck correlation among variables across datasets:\n\n\nCode\np &lt;- jldramp %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin_log) %&gt;%\n          left_join(jldflow %&gt;% select(broodyr, jld_winmin, jld_summean, jld_peakmag, jld_peaktime)) %&gt;%\n          left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_peakmag, natq_peaktime)) %&gt;%\n          #left_join(natflow %&gt;% filter(flowstn == \"SnakeBeFlat\") %&gt;% select(broodyr, natq_winmean)) %&gt;%\n          left_join(airtemp %&gt;% filter(tempstn == \"moose\") %&gt;% select(broodyr, temp_falmean, temp_winmean, temp_sprmean, temp_summean))\nrange(cor(p, use = \"pairwise.complete.obs\")[upper.tri(cor(p, use = \"pairwise.complete.obs\"))])\n\n\n[1] -0.5061091  0.5862950\n\n\nCode\nggpairs(p, progress = FALSE)\n\n\n\n\n\n\n\n\n\nPost 1989\n\n\nCode\np &lt;- jldramp %&gt;% filter(broodyr &gt;= 1989) %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin_log) %&gt;%\n          left_join(jldflow %&gt;% filter(broodyr &gt;= 1989) %&gt;% select(broodyr, jld_winmin, jld_summean, jld_peakmag, jld_peaktime)) %&gt;%\n          left_join(natflow %&gt;% filter(broodyr &gt;= 1989) %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_peakmag, natq_peaktime)) %&gt;%\n          #left_join(natflow %&gt;% filter(broodyr &gt;= 1989) %&gt;% filter(flowstn == \"SnakeBeFlat\") %&gt;% select(broodyr, natq_winmean)) %&gt;%\n          left_join(airtemp %&gt;% filter(broodyr &gt;= 1989) %&gt;% filter(tempstn == \"moose\") %&gt;% select(broodyr, temp_falmean, temp_winmean, temp_sprmean, temp_summean))\nrange(cor(p, use = \"pairwise.complete.obs\")[upper.tri(cor(p, use = \"pairwise.complete.obs\"))])\n\n\n[1] -0.5481930  0.5453191\n\n\nCode\nggpairs(p, progress = FALSE)\n\n\n\n\n\n\n\n\n\nExperienced flow\n\n\nCode\np &lt;- jldramp %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin_log) %&gt;%\n          left_join(jldflow %&gt;% select(broodyr, jld_winvar, jld_summean)) %&gt;%\n          #left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_peakmag, natq_peaktime)) %&gt;%\n          left_join(natflow %&gt;% filter(flowstn == \"SnakeBeFlat\") %&gt;% select(broodyr, natq_winmean, natq_peakmag, natq_peaktime)) %&gt;%\n          left_join(airtemp %&gt;% filter(tempstn == \"moose\") %&gt;% select(broodyr, temp_falmean, temp_winmean, temp_sprmean, temp_summean)) %&gt;% select(-broodyr)\nrange(cor(p, use = \"complete.obs\")[upper.tri(cor(p, use = \"complete.obs\"))])\n\n\n[1] -0.5976980  0.6003041\n\n\nCode\nggpairs(p, progress = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Test specific variables\n\n3.2.2.1 Winter flow\nJLD and natural winter flow highly correlated, especially after 1989\n\n\nCode\nddd &lt;- jldflow %&gt;% select(broodyr, jld_winmean) %&gt;% left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_winmean))\ncor.test(ddd$jld_winmean, ddd$natq_winmean)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd$jld_winmean and ddd$natq_winmean\nt = 5.6337, df = 46, p-value = 1.022e-06\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4335332 0.7812567\nsample estimates:\n      cor \n0.6389597 \n\n\nCode\nddd1 &lt;- ddd %&gt;% filter(broodyr &gt;= 1989)\ncor.test(ddd1$jld_winmean, ddd1$natq_winmean)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_winmean and ddd1$natq_winmean\nt = 7.227, df = 32, p-value = 3.29e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6123541 0.8889125\nsample estimates:\n      cor \n0.7874557 \n\n\nCode\nddd1 &lt;- ddd %&gt;% filter(broodyr &lt; 1989)\ncor.test(ddd1$jld_winmean, ddd1$natq_winmean)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_winmean and ddd1$natq_winmean\nt = 1.563, df = 12, p-value = 0.144\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1526044  0.7731439\nsample estimates:\n      cor \n0.4112756 \n\n\n\n\n3.2.2.2 Peak timing\nWhile the timing of peak natural vs. managed flows are not correlated during the full or either partial time period, this may be driven by years of missing data for JLD peak flows…where there was not a JLD peak. Time series plots are suspicious\n\n\nCode\n# peak timing...ok...\nddd &lt;- jldflow %&gt;% select(broodyr, jld_peaktime) %&gt;% left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_peaktime))\ncor.test(ddd$jld_peaktime, ddd$natq_peaktime)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd$jld_peaktime and ddd$natq_peaktime\nt = -0.43671, df = 36, p-value = 0.6649\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3833791  0.2529610\nsample estimates:\n        cor \n-0.07259273 \n\n\nCode\nplot(ddd$jld_peaktime, ddd$natq_peaktime, ylab = \"brood year DOY\", xlab = \"year\")\n\n\n\n\n\n\n\n\n\nCode\nplot(jld_peaktime ~ broodyr, ddd, type = \"b\", col = \"blue\")\nlines(natq_peaktime ~ broodyr, ddd, type = \"b\", col = \"red\")\nlegend(\"bottomright\", legend = c(\"JLD\", \"natural\"), lty = 1, col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\n\nCode\nddd1 &lt;- ddd %&gt;% filter(broodyr &gt;= 1989)\ncor.test(ddd1$jld_peaktime, ddd1$natq_peaktime)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_peaktime and ddd1$natq_peaktime\nt = -0.62341, df = 23, p-value = 0.5392\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.4986378  0.2805140\nsample estimates:\n       cor \n-0.1289046 \n\n\nCode\n#plot(ddd1$jld_peaktime, ddd1$natq_peaktime)\n#abline(a = 0, b = 1)\nddd1 &lt;- ddd %&gt;% filter(broodyr &lt; 1989)\ncor.test(ddd1$jld_peaktime, ddd1$natq_peaktime)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_peaktime and ddd1$natq_peaktime\nt = 0.013513, df = 11, p-value = 0.9895\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5481414  0.5538164\nsample estimates:\n        cor \n0.004074438 \n\n\nCode\n#plot(ddd1$jld_peaktime, ddd1$natq_peaktime)\n\n\n\n\n3.2.2.3 Peak magnitude\nNo multicollinearity issues between the magnitude of peak natural vs. managed flows, although these variables are somewhat correlated prior to 1989.\n\n\nCode\n# peak magnitude...ok...\nddd &lt;- jldflow %&gt;% select(broodyr, jld_peakmag) %&gt;% left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_peakmag))\ncor.test(ddd$jld_peakmag, ddd$natq_peakmag)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd$jld_peakmag and ddd$natq_peakmag\nt = 4.9086, df = 46, p-value = 1.194e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3625576 0.7461337\nsample estimates:\n     cor \n0.586295 \n\n\nCode\nplot(jld_peakmag ~ broodyr, ddd, type = \"b\", col = \"blue\", ylim = c(3000,20000))\nlines(natq_peakmag ~ broodyr, ddd, type = \"b\", col = \"red\")\nlegend(\"topleft\", legend = c(\"JLD\", \"natural\"), lty = 1, col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\n\nCode\nddd1 &lt;- ddd %&gt;% filter(broodyr &gt;= 1989)\ncor.test(ddd1$jld_peakmag, ddd1$natq_peakmag)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_peakmag and ddd1$natq_peakmag\nt = 3.6311, df = 32, p-value = 0.0009749\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2471686 0.7426824\nsample estimates:\n      cor \n0.5401836 \n\n\nCode\nddd1 &lt;- ddd %&gt;% filter(broodyr &lt; 1989)\ncor.test(ddd1$jld_peakmag, ddd1$natq_peakmag)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_peakmag and ddd1$natq_peakmag\nt = 3.2601, df = 12, p-value = 0.006828\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2431875 0.8916793\nsample estimates:\n      cor \n0.6853377 \n\n\n\n\n3.2.2.4 JLD peak mag and JLD win min\nJLD peak flow magnitude and combined winter mean flow are correlated (&gt;0.6)…perhaps an artifact of “good water years”\n\n\nCode\nddd &lt;- jldflow %&gt;% select(broodyr, jld_peakmag, jld_winmin)\ncor.test(ddd$jld_peakmag, ddd$jld_winmin)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd$jld_peakmag and ddd$jld_winmin\nt = 2.2111, df = 61, p-value = 0.03079\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.02640982 0.48727185\nsample estimates:\n      cor \n0.2723925 \n\n\nCode\nplot(jld_peakmag ~ broodyr, ddd, type = \"b\", col = \"blue\")\npar(new = TRUE)\nplot(jld_winmin ~ broodyr, ddd, type = \"b\", col = \"red\")\nlegend(\"topleft\", legend = c(\"JLD peak mag\", \"Combined winter mean\"), lty = 1, col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\n\nCode\nddd1 &lt;- ddd %&gt;% filter(broodyr &gt;= 1989)\ncor.test(ddd1$jld_peakmag, ddd1$jld_winmin)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_peakmag and ddd1$jld_winmin\nt = 2.4703, df = 32, p-value = 0.01902\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.07173556 0.65034644\nsample estimates:\n      cor \n0.4001932 \n\n\nCode\nddd1 &lt;- ddd %&gt;% filter(broodyr &lt; 1989)\ncor.test(ddd1$jld_peakmag, ddd1$jld_winmin)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  ddd1$jld_peakmag and ddd1$jld_winmin\nt = 1.9257, df = 27, p-value = 0.06473\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.02176591  0.63335086\nsample estimates:\n     cor \n0.347512 \n\n\n\n\n\n3.2.3 Lag correlations\nCheck correlations between variables in year t and t+1 (to separate age-0 and age-1 effects).\nWinter variation is the only variable that is moderately correlated between time t and t+1 (0.65)\n\n\nCode\ncor.test(jldramp$jld_rampdur, lead(jldramp$jld_rampdur))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  jldramp$jld_rampdur and lead(jldramp$jld_rampdur)\nt = 0.96669, df = 60, p-value = 0.3376\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1299488  0.3623978\nsample estimates:\n      cor \n0.1238389 \n\n\nCode\ncor.test(jldramp$jld_rampratemindoy, lead(jldramp$jld_rampratemindoy))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  jldramp$jld_rampratemindoy and lead(jldramp$jld_rampratemindoy)\nt = 4.2439, df = 60, p-value = 7.735e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2621889 0.6520108\nsample estimates:\n      cor \n0.4804914 \n\n\nCode\ncor.test(jldramp$jld_rampratemin_log, lead(jldramp$jld_rampratemin_log))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  jldramp$jld_rampratemin_log and lead(jldramp$jld_rampratemin_log)\nt = 0.70935, df = 60, p-value = 0.4809\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1622692  0.3333699\nsample estimates:\n       cor \n0.09119508 \n\n\nCode\ncor.test(jldflow$jld_winmin, lead(jldflow$jld_winmin))                  # pearsons r = 0.65\n\n\n\n    Pearson's product-moment correlation\n\ndata:  jldflow$jld_winmin and lead(jldflow$jld_winmin)\nt = 4.3865, df = 60, p-value = 4.729e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2771030 0.6611604\nsample estimates:\n      cor \n0.4927661 \n\n\nCode\ncor.test(jldflow$jld_summean, lead(jldflow$jld_summean))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  jldflow$jld_summean and lead(jldflow$jld_summean)\nt = 0.27338, df = 60, p-value = 0.7855\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2164039  0.2825498\nsample estimates:\n       cor \n0.03527073 \n\n\nCode\ncor.test(jldflow$jld_peakmag, lead(jldflow$jld_peakmag))                  # pearsons r = 0.65\n\n\n\n    Pearson's product-moment correlation\n\ndata:  jldflow$jld_peakmag and lead(jldflow$jld_peakmag)\nt = 2.5116, df = 60, p-value = 0.01473\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.06357118 0.51828219\nsample estimates:\n      cor \n0.3084419 \n\n\nCode\ncor.test(jldflow$jld_peaktime, lead(jldflow$jld_peaktime))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  jldflow$jld_peaktime and lead(jldflow$jld_peaktime)\nt = 1.0467, df = 44, p-value = 0.3009\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1407981  0.4268542\nsample estimates:\n      cor \n0.1558709 \n\n\nCode\nd &lt;- natflow %&gt;% filter(flowstn == \"SnakeNat\")\ncor.test(d$natq_peakmag, lead(d$natq_peakmag))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  d$natq_peakmag and lead(d$natq_peakmag)\nt = 0.17576, df = 45, p-value = 0.8613\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2629533  0.3110188\nsample estimates:\n       cor \n0.02619124 \n\n\nCode\ncor.test(d$natq_peaktime, lead(d$natq_peaktime))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  d$natq_peaktime and lead(d$natq_peaktime)\nt = 0.85953, df = 45, p-value = 0.3946\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1661387  0.3996718\nsample estimates:\n      cor \n0.1270916 \n\n\nCode\nd &lt;- airtemp %&gt;% filter(tempstn == \"moose\")\ncor.test(d$temp_falmean, lead(d$temp_falmean))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  d$temp_falmean and lead(d$temp_falmean)\nt = 2.5647, df = 56, p-value = 0.01303\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.07193934 0.53749544\nsample estimates:\n      cor \n0.3242108 \n\n\nCode\ncor.test(d$temp_winmean, lead(d$temp_winmean))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  d$temp_winmean and lead(d$temp_winmean)\nt = 0.82595, df = 58, p-value = 0.4122\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1502169  0.3521051\nsample estimates:\n      cor \n0.1078205 \n\n\nCode\ncor.test(d$temp_sprmean, lead(d$temp_sprmean))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  d$temp_sprmean and lead(d$temp_sprmean)\nt = 0.96896, df = 52, p-value = 0.337\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1395630  0.3871302\nsample estimates:\n      cor \n0.1331742 \n\n\nCode\ncor.test(d$temp_summean, lead(d$temp_summean))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  d$temp_summean and lead(d$temp_summean)\nt = 1.3246, df = 53, p-value = 0.191\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.09059664  0.42415727\nsample estimates:\n      cor \n0.1790029 \n\n\n\n\nCode\n# correlations among natural, managed, and combined winter flow\nddd &lt;- jldflow %&gt;% select(broodyr, jld_annmin) %&gt;%\n  left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_annmin)) %&gt;% \n  left_join(natflow %&gt;% filter(flowstn == \"SnakeBeFlat\") %&gt;% select(broodyr, natq_annmin) %&gt;% rename(expq_annmin = natq_annmin)) \nggpairs(ddd)\nggpairs(ddd %&gt;% filter(broodyr &gt;= 1989))\n\nddd &lt;- jldflow %&gt;% select(broodyr, jld_peakmag) %&gt;%\n  left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_peakmag)) %&gt;% \n  left_join(natflow %&gt;% filter(flowstn == \"SnakeBeFlat\") %&gt;% select(broodyr, natq_peakmag) %&gt;% rename(expq_peakmag = natq_peakmag)) \nggpairs(ddd)\nggpairs(ddd %&gt;% filter(broodyr &gt;= 1989))\n\nddd &lt;- jldflow %&gt;% select(broodyr, jld_peaktime) %&gt;%\n  left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_peaktime)) %&gt;% \n  left_join(natflow %&gt;% filter(flowstn == \"SnakeBeFlat\") %&gt;% select(broodyr, natq_peaktime) %&gt;% rename(expq_peaktime = natq_peaktime)) \nggpairs(ddd)\nggpairs(ddd %&gt;% filter(broodyr &gt;= 1989))\n\n\n# winter flow time series plots\nddd &lt;- jldflow %&gt;% select(broodyr, jld_annmin) %&gt;% \n  left_join(natflow %&gt;% filter(flowstn == \"SnakeNat\") %&gt;% select(broodyr, natq_annmin)) %&gt;% \n  mutate(tot_annmin = jld_annmin + natq_annmin,\n         prop_annmin = jld_annmin/tot_annmin) %&gt;% filter(!is.na(tot_annmin))\nddd$cor &lt;- NA\nddd$cor[5:44] &lt;- rollapply(ddd, width = 9, function(x) abs(cor(x[,2], x[,3])), by.column = FALSE)\n\npar(mfrow = c(3,1), mar = c(3,4,0.5,0.5), mgp = c(2.5,1,0))\nplot(tot_annmin ~ broodyr, ddd, type = \"n\", ylim = c(0,2500), xlab = \"\", ylab = \"Winter flow (cfs)\", bty = \"l\")\npolygon(x = c(ddd$broodyr, rev(ddd$broodyr)), y = c(rep(0, times = dim(ddd)[1]), rev(ddd$tot_annmin)), border = NA, col = \"grey\")\npolygon(x = c(ddd$broodyr, rev(ddd$broodyr)), y = c(rep(0, times = dim(ddd)[1]), rev(ddd$natq_annmin)), border = NA, col = \"white\")\npolygon(x = c(ddd$broodyr, rev(ddd$broodyr)), y = c(rep(0, times = dim(ddd)[1]), rev(ddd$jld_annmin)), border = NA, col = \"white\")\npolygon(x = c(ddd$broodyr, rev(ddd$broodyr)), y = c(rep(0, times = dim(ddd)[1]), rev(ddd$natq_annmin)), border = NA, col = scales::alpha(\"darkorchid2\", 1))\npolygon(x = c(ddd$broodyr, rev(ddd$broodyr)), y = c(rep(0, times = dim(ddd)[1]), rev(ddd$jld_annmin)), border = NA, col = scales::alpha(\"goldenrod1\", 1))\nlegend(\"topright\", legend = c(\"Total\", \"Natural\", \"Managed\"), fill = c(\"grey\", \"darkorchid2\", \"goldenrod1\"), bty = \"n\")\nplot(prop_annmin ~ broodyr, ddd, type = \"l\", bty = \"l\", xlab = \"\", ylab = \"JLD contribution to winter flow\")\npoints(prop_annmin ~ broodyr, ddd, pch = 16)\nplot(cor ~ broodyr, ddd, type = \"l\", bty = \"l\", xlab = \"\", ylab = \"Correlation (rolling 9-year window)\", ylim = c(0,1))\npoints(cor ~ broodyr, ddd, pch = 16)\nabline(h = 0.6, lty = 2, col = \"red\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Join Fish and Env. Data</span>"
    ]
  },
  {
    "objectID": "JoinFishDataWithCovariates.html#select-covariates-and-standardize",
    "href": "JoinFishDataWithCovariates.html#select-covariates-and-standardize",
    "title": "3  Join Fish and Env. Data",
    "section": "3.3 Select Covariates and Standardize",
    "text": "3.3 Select Covariates and Standardize\nPull out relevant variables, trim to temporal extent of redd count data (by brood year. I.e., redd counts start at 1971 but environmental data starts at 1967), and standardize (mean centered and scaled).\n\n\nCode\n# Managed flow variables\ncovsrc_jldq &lt;- jldramp %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin_log) %&gt;%\n  filter(broodyr &gt;= minby) %&gt;%\n  left_join(jldflow %&gt;% select(broodyr, jld_winmean, jld_winmin, jld_winvar, jld_summean, jld_peakmag, jld_peaktime)) %&gt;%\n  #mutate(jld_winmin_log = ifelse(jld_winmin_log &lt; 4, NA, jld_winmin_log)) %&gt;%\n  mutate(z_jld_rampdur = scale(jld_rampdur, center = TRUE, scale = TRUE)[,1], \n         z_jld_rampratemindoy = scale(jld_rampratemindoy, center = TRUE, scale = TRUE)[,1], \n         z_jld_rampratemin_log = scale(jld_rampratemin_log, center = TRUE, scale = TRUE)[,1],\n         z_jld_winmean = scale(jld_winmean, center = TRUE, scale = TRUE)[,1],\n         z_jld_winmin = scale(jld_winmin, center = TRUE, scale = TRUE)[,1],\n         z_jld_winvar = scale(jld_winvar, center = TRUE, scale = TRUE)[,1],\n         z_jld_summean = scale(jld_summean, center = TRUE, scale = TRUE)[,1],\n         z_jld_peakmag = scale(jld_peakmag, center = TRUE, scale = TRUE)[,1],\n         z_jld_peaktime = scale(jld_peaktime, center = TRUE, scale = TRUE)[,1])\n#ggpairs(covsrc_jldq %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin_log, jld_winmean, jld_winmin, jld_winvar, jld_summean, jld_peakmag, jld_peaktime))\n\n# Managed flow variables - ramp-down only\ncovsrc_jldq_rd &lt;- jldramp %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin_log) %&gt;%\n  filter(broodyr &gt;= minby) %&gt;%\n  #mutate(jld_rampratemin = ifelse(jld_rampratemin &lt; -2000, NA, jld_rampratemin)) %&gt;%\n  mutate(z_jld_rampdur = scale(jld_rampdur, center = TRUE, scale = TRUE)[,1], \n         z_jld_rampratemindoy = scale(jld_rampratemindoy, center = TRUE, scale = TRUE)[,1], \n         z_jld_rampratemin_log = scale(jld_rampratemin_log, center = TRUE, scale = TRUE)[,1])\n#ggpairs(covsrc_jldq_rd %&gt;% select(broodyr, jld_rampdur, jld_rampratemindoy, jld_rampratemin_log))\n\n# Natural/wild flow variables \ncovsrc_natq &lt;- natflow %&gt;% filter(flowstn %in% c(\"SnakeNat\")) %&gt;% # make sure flow station is correct!\n  select(flowstn, broodyr, natq_falmean_log, natq_winmean_log, natq_sprmean_log, natq_summean_log, natq_winvar, natq_peakmag, natq_peaktime) %&gt;% #rename(flowstn = site) %&gt;% \n  filter(broodyr &gt;= minby) %&gt;%\n  mutate(z_natq_winvar = scale(natq_winvar, center = TRUE, scale = TRUE)[,1]) %&gt;%\n  mutate(z_natq_falmean_log = scale(natq_falmean_log, center = TRUE, scale = TRUE)[,1], \n         z_natq_winmean_log = scale(natq_winmean_log, center = TRUE, scale = TRUE)[,1], \n         z_natq_sprmean_log = scale(natq_sprmean_log, center = TRUE, scale = TRUE)[,1], \n         z_natq_summean_log = scale(natq_summean_log, center = TRUE, scale = TRUE)[,1], \n         z_natq_peakmag = scale(natq_peakmag, center = TRUE, scale = TRUE)[,1], \n         z_natq_peaktime = scale(natq_peaktime, center = TRUE, scale = TRUE)[,1]) %&gt;% ungroup()\n#ggpairs(covsrc_natq %&gt;% select(broodyr, natq_falmean_log, natq_winmean_log, natq_sprmean_log, natq_summean_log, natq_winvar, natq_peakmag, natq_peaktime))\n\n# Experienced flow variables\ncovsrc_expq &lt;- natflow %&gt;% filter(flowstn %in% c(\"SnakeBeFlat\")) %&gt;%\n  select(flowstn, broodyr, natq_winmean, natq_winvar, natq_summean, natq_peakmag, natq_peaktime) %&gt;%\n  filter(broodyr &gt;= minby) %&gt;%\n  mutate(z_natq_winmean = scale(natq_winmean, center = TRUE, scale = TRUE)[,1], \n         z_natq_winvar = scale(natq_winvar, center = TRUE, scale = TRUE)[,1], \n         z_natq_summean = scale(natq_summean, center = TRUE, scale = TRUE)[,1], \n         z_natq_peakmag = scale(natq_peakmag, center = TRUE, scale = TRUE)[,1], \n         z_natq_peaktime = scale(natq_peaktime, center = TRUE, scale = TRUE)[,1])\n#ggpairs(covsrc_expq %&gt;% select(broodyr, natq_winmean, natq_winvar, natq_summean, natq_peakmag, natq_peaktime))\n\n# Temperature variables\ncovsrc_temp &lt;- airtemp %&gt;% filter(tempstn %in% c(\"moose\")) %&gt;%\n  select(tempstn, broodyr, temp_falmean, temp_winmean, temp_sprmean, temp_summean) %&gt;% #rename(tempstn = site) %&gt;% #group_by(tempstn) %&gt;%\n  filter(broodyr &gt;= minby) %&gt;%\n  mutate(z_temp_falmean = scale(temp_falmean, center = TRUE, scale = TRUE)[,1], \n         z_temp_winmean = scale(temp_winmean, center = TRUE, scale = TRUE)[,1], \n         z_temp_sprmean = scale(temp_sprmean, center = TRUE, scale = TRUE)[,1], \n         z_temp_summean = scale(temp_summean, center = TRUE, scale = TRUE)[,1]) %&gt;% ungroup()\n#ggpairs(covsrc_temp %&gt;% select(broodyr, temp_falmean, temp_winmean, temp_sprmean, temp_summean))\n\n\nCreate and write out summary tables (means and standard deviations)\n\n\nCode\n# JLD Flow\ncovsrc_jldq_summary &lt;- tibble(cov = c(\"z_jld_rampdur\", \"z_jld_rampratemindoy\", \"z_jld_rampratemin_log\", \"z_jld_winmean\", \"z_jld_winmin\", \"z_jld_winvar\", \"z_jld_summean\", \"z_jld_peakmag\", \"z_jld_peaktime\"),\n                              mean = c(attr(scale(covsrc_jldq$jld_rampdur, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_rampratemindoy, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_rampratemin_log, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_winmean, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_winmin, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_winvar, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_summean, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_peakmag, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_jldq$jld_peaktime, center = TRUE, scale = TRUE), \"scaled:center\")),\n                              sd = c(attr(scale(covsrc_jldq$jld_rampdur, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_rampratemindoy, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_rampratemin_log, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_winmean, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_winmin, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_winvar, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_summean, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_peakmag, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_jldq$jld_peaktime, center = TRUE, scale = TRUE), \"scaled:scale\")))\nwrite_csv(covsrc_jldq_summary, \"Data/Derived/ManagedFlow_SummaryMeanSD_1967-2022.csv\")\n\n# Natural Flow\ncovsrc_natq_summary &lt;- tibble(cov = c(\"z_natq_falmean_log\", \"z_natq_winmean_log\", \"z_natq_sprmean_log\", \"z_natq_summean_log\", \"z_natq_winvar\", \"z_natq_peakmag\", \"z_natq_peaktime\"),\n                              mean = c(attr(scale(covsrc_natq$natq_falmean_log, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_natq$natq_winmean_log, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_natq$natq_sprmean_log, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_natq$natq_summean_log, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_natq$natq_winvar, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_natq$natq_peakmag, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_natq$natq_peaktime, center = TRUE, scale = TRUE), \"scaled:center\")),\n                              sd = c(attr(scale(covsrc_natq$natq_falmean_log, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_natq$natq_winmean_log, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_natq$natq_sprmean_log, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_natq$natq_summean_log, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_natq$natq_winvar, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_natq$natq_peakmag, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_natq$natq_peaktime, center = TRUE, scale = TRUE), \"scaled:scale\")))\nwrite_csv(covsrc_natq_summary, \"Data/Derived/NaturalFlow_SummaryMeanSD_1975-2022.csv\")\n\n# Experienced Flow\ncovsrc_expq_summary &lt;- tibble(cov = c(\"z_expq_winmean\", \"z_expq_winvar\", \"z_expq_summean\", \"z_expq_peakmag\", \"z_expq_peaktime\"),\n                              mean = c(attr(scale(covsrc_expq$natq_winmean, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_expq$natq_winvar, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_expq$natq_summean, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_expq$natq_peakmag, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_expq$natq_peaktime, center = TRUE, scale = TRUE), \"scaled:center\")),\n                              sd = c(attr(scale(covsrc_expq$natq_winmean, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_expq$natq_winvar, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_expq$natq_summean, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_expq$natq_peakmag, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_expq$natq_peaktime, center = TRUE, scale = TRUE), \"scaled:scale\")))\nwrite_csv(covsrc_expq_summary, \"Data/Derived/ExperiencedFlow_SummaryMeanSD_1975-2022.csv\")\n\n# Temperature\ncovsrc_temp_summary &lt;- tibble(cov = c(\"z_temp_falmean\", \"z_temp_winmean\", \"z_temp_sprmean\", \"z_temp_summean\"),\n                              mean = c(attr(scale(covsrc_temp$temp_falmean, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_temp$temp_winmean, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_temp$temp_sprmean, center = TRUE, scale = TRUE), \"scaled:center\"),\n                                       attr(scale(covsrc_temp$temp_summean, center = TRUE, scale = TRUE), \"scaled:center\")),\n                              sd = c(attr(scale(covsrc_temp$temp_falmean, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_temp$temp_winmean, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_temp$temp_sprmean, center = TRUE, scale = TRUE), \"scaled:scale\"),\n                                     attr(scale(covsrc_temp$temp_summean, center = TRUE, scale = TRUE), \"scaled:scale\")))\nwrite_csv(covsrc_temp_summary, \"Data/Derived/Temperature_SummaryMeanSD_1967-2022.csv\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Join Fish and Env. Data</span>"
    ]
  },
  {
    "objectID": "JoinFishDataWithCovariates.html#join-covariate-and-fish-data",
    "href": "JoinFishDataWithCovariates.html#join-covariate-and-fish-data",
    "title": "3  Join Fish and Env. Data",
    "section": "3.4 Join Covariate and Fish Data",
    "text": "3.4 Join Covariate and Fish Data\n\n3.4.1 Separate natural and managed flow components\nAge-0 (4-year lag)\n\n\nCode\nredds3a &lt;- redds2\nredds3a$broodyr &lt;- redds3a$year - 4 # create broodyr variable for joining\nredds3a$tempstn &lt;- ifelse(redds3a$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"afton\", \"moose\") # basin ID to match to NWS temp station\nredds3a$flowstn &lt;- ifelse(redds3a$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"Salt\", \"SnakeNat\") # basin ID to match to USGS flow station \nredds3a &lt;- redds3a %&gt;% \n  left_join(covsrc_jldq, by = \"broodyr\") %&gt;% \n  left_join(covsrc_natq, by = c(\"broodyr\", \"flowstn\")) %&gt;% \n  left_join(covsrc_temp, by = c(\"broodyr\", \"tempstn\"))\n\n\nAge-1 (3-year lag)\n\n\nCode\nredds3b &lt;- redds2\nredds3b$broodyr &lt;- redds3b$year - 3 # create broodyr variable for joining\nredds3b$tempstn &lt;- ifelse(redds3b$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"afton\", \"moose\") # basin ID to match to NWS temp station\nredds3b$flowstn &lt;- ifelse(redds3b$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"Salt\", \"SnakeNat\") # basin ID to match to USGS flow station \nredds3b &lt;- redds3b %&gt;% \n  left_join(covsrc_jldq, by = \"broodyr\") %&gt;% \n  left_join(covsrc_natq, by = c(\"broodyr\", \"flowstn\")) %&gt;% \n  left_join(covsrc_temp, by = c(\"broodyr\", \"tempstn\"))\n\n\n\n\n3.4.2 Experienced flow\nAge-0 (4-year lag)\n\n\nCode\nredds3c &lt;- redds2\nredds3c$broodyr &lt;- redds3c$year - 4 # create broodyr variable for joining\nredds3c$tempstn &lt;- ifelse(redds3c$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"afton\", \"moose\") # basin ID to match to NWS temp station\nredds3c$flowstn &lt;- ifelse(redds3c$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"Salt\", \"SnakeBeFlat\") # basin ID to match to USGS flow station \nredds3c &lt;- redds3c %&gt;% \n  left_join(covsrc_jldq_rd, by = \"broodyr\") %&gt;% \n  left_join(covsrc_expq, by = c(\"broodyr\", \"flowstn\")) %&gt;% \n  left_join(covsrc_temp, by = c(\"broodyr\", \"tempstn\"))\n\n\nAge-1 (3-year lag)\n\n\nCode\nredds3d &lt;- redds2\nredds3d$broodyr &lt;- redds3d$year - 3 # create broodyr variable for joining\nredds3d$tempstn &lt;- ifelse(redds3d$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"afton\", \"moose\") # basin ID to match to NWS temp station\nredds3d$flowstn &lt;- ifelse(redds3d$stream %in% c(\"Christiansen\", \"Dave\", \"Laker\"), \"Salt\", \"SnakeBeFlat\") # basin ID to match to USGS flow station \nredds3d &lt;- redds3d %&gt;% \n  left_join(covsrc_jldq_rd, by = \"broodyr\") %&gt;% \n  left_join(covsrc_expq, by = c(\"broodyr\", \"flowstn\")) %&gt;% \n  left_join(covsrc_temp, by = c(\"broodyr\", \"tempstn\"))\n\n\n\n\n3.4.3 Write out data files\n\n\nCode\nwrite_csv(redds3a, \"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_SeparateFlowComponents_age0.csv\")\nwrite_csv(redds3b, \"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_SeparateFlowComponents_age1.csv\")\nwrite_csv(redds3c, \"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_ExperiencedFlow_age0.csv\")\nwrite_csv(redds3d, \"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_ExperiencedFlow_age1.csv\")\n\n\n\n\nCode\nplot(natq_winmean ~ broodyr, covsrc_expq, type = \"b\")\nplot(natq_winvar ~ broodyr, covsrc_expq, type = \"b\")\nplot(natq_peakmag ~ broodyr, covsrc_expq, type = \"b\")\nplot(natq_peaktime ~ broodyr, covsrc_expq, type = \"b\")",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Join Fish and Env. Data</span>"
    ]
  },
  {
    "objectID": "ReddCountsRicker.html",
    "href": "ReddCountsRicker.html",
    "title": "4  Stock-Recruitment Analysis",
    "section": "",
    "text": "4.1 Data\nPurpose: Fit hierarchical Ricker stock-recruitment model to understand environmental effects on population productivity\nNotes:\nFirst, use this to pull fish data\nCode\ndat &lt;- read_csv(\"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_SeparateFlowComponents_age0.csv\")\nPull covariate data for age-0, combine experienced and natural flow datasets\nCode\ndat0 &lt;- read_csv(\"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_SeparateFlowComponents_age0.csv\")\ndat0b &lt;- read_csv(\"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_ExperiencedFlow_age0.csv\") %&gt;%\n  select(year, stream, natq_winmean, natq_winvar, natq_peakmag, natq_peaktime, z_natq_winmean, z_natq_winvar, z_natq_peakmag, z_natq_peaktime) %&gt;%\n  rename(expq_winmean = natq_winmean,\n         expq_winvar = natq_winvar,\n         expq_peakmag = natq_peakmag,\n         expq_peaktime = natq_peaktime,\n         z_expq_winmean = z_natq_winmean,\n         z_expq_winvar = z_natq_winvar,\n         z_expq_peakmag = z_natq_peakmag,\n         z_expq_peaktime = z_natq_peaktime)\ndat0 &lt;- dat0 %&gt;% left_join(dat0b)\nPull covariate data for age-1, combine experienced and natural flow datasets\nCode\ndat1 &lt;- read_csv(\"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_SeparateFlowComponents_age1.csv\")\ndat1b &lt;- read_csv(\"Data/Derived/ReddCounts_WGFD_1971-2021_cleaned_withFlowTempCovariates_ExperiencedFlow_age1.csv\") %&gt;%\n  select(year, stream, natq_winmean, natq_winvar, natq_peakmag, natq_peaktime, z_natq_winmean, z_natq_winvar, z_natq_peakmag, z_natq_peaktime) %&gt;%\n  rename(expq_winmean = natq_winmean,\n         expq_winvar = natq_winvar,\n         expq_peakmag = natq_peakmag,\n         expq_peaktime = natq_peaktime,\n         z_expq_winmean = z_natq_winmean,\n         z_expq_winvar = z_natq_winvar,\n         z_expq_peakmag = z_natq_peakmag,\n         z_expq_peaktime = z_natq_peaktime)\ndat1 &lt;- dat1 %&gt;% left_join(dat1b)\nDrop Cody (very little data), Salt River tribs, and “ghost years”\nCode\ndat &lt;- dat %&gt;% \n  filter(!stream %in% c(\"Cody\", \"Christiansen\", \"Dave\", \"Laker\")) %&gt;%\n  filter(!(stream == \"Cowboy Cabin\" & year %in% c(1980:1981))) %&gt;%\n  filter(!(stream == \"Flat\" & year %in% c(1976:1979))) %&gt;%\n  filter(!(stream == \"Spring\" & year %in% c(1988:1992)))\nCreate summary table\nCode\nsummary.dat &lt;- dat %&gt;% filter(!is.na(reddsperkm)) %&gt;% group_by(stream) %&gt;% summarize('lat' = unique(lat), 'long' = unique(long), 'startyr' = min(year), 'endyr' = max(year), 'n.year' = length(unique(year))) %&gt;% arrange(stream) %&gt;% ungroup()\ndatatable(summary.dat)\n\n\n\n\n\n\nCode\nwrite_csv(summary.dat, \"ReddCounts_DataSummary.csv\")\nPlot stock-recruit data\nCode\ng &lt;- ggplot(dat, aes(x = reddsperkm_lag4, y = reddsperkm, color = broodyr)) +\n  theme_bw() +\n  geom_smooth(color = \"black\") +\n  geom_point(alpha = 0.75) +\n  facet_wrap(~ stream, scales = 'free', ncol = 4) +\n  xlab('Spawning redd density (redds/km)') +\n  ylab('Recruitment redd density (redds/km)') +\n  theme(panel.grid = element_blank())\nplot(g)\nPlot productivity by stock/spawners\nCode\ng &lt;- ggplot(dat, aes(x = reddsperkm_lag4, y = log(reddsperkm/reddsperkm_lag4), color = broodyr)) +\n  theme_bw() +\n  geom_smooth(method ='lm', color = \"black\") +\n  geom_point(alpha = 0.75) +\n  facet_wrap(~ stream, scales = 'free', ncol = 4) +\n  xlab('Spawning redd density (redds/km)') +\n  ylab('ln(Recruits/Spawner)') +\n  theme(panel.grid = element_blank())\nplot(g)\nAdd misc. variables (currently not used in the model)\nCode\n# JLD mgmt regime\ndat &lt;- dat %&gt;% mutate(regime = ifelse(year &lt; 1989, 0, 1))\n\n# Distance from JLD\ndjld &lt;- read_csv(\"Flowline Distance/ReddCount_Sites_JLDDistance.csv\") %&gt;%\n  filter(!stream %in% c(\"Dave\", \"Snake River Side Channel\", \"Spring\"))\nHow much of the variation in productivity is explained by density-dependence alone? (sensu Jones et al. 2020)\nCode\ndat2 &lt;- dat %&gt;% mutate(lnRS = log(reddsperkm / reddsperkm_lag4), \n                       stream = as_factor(stream))\nsummary(lm(lnRS ~ reddsperkm_lag4 + stream:reddsperkm_lag4, dat2)) # ~37%\n\n\n\nCall:\nlm(formula = lnRS ~ reddsperkm_lag4 + stream:reddsperkm_lag4, \n    data = dat2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.65491 -0.32585  0.04252  0.32878  2.16889 \n\nCoefficients:\n                                                Estimate Std. Error t value\n(Intercept)                                     1.059469   0.087723  12.078\nreddsperkm_lag4                                -0.012519   0.002065  -6.063\nreddsperkm_lag4:streamBlacktail                 0.009026   0.001984   4.550\nreddsperkm_lag4:streamBlue Crane               -0.050926   0.008190  -6.218\nreddsperkm_lag4:streamCowboy Cabin             -0.013250   0.004807  -2.757\nreddsperkm_lag4:streamFish                     -0.010025   0.003744  -2.678\nreddsperkm_lag4:streamFlat                     -0.044523   0.008485  -5.247\nreddsperkm_lag4:streamLittle Bar BC            -0.017217   0.003412  -5.046\nreddsperkm_lag4:streamNowlin                   -0.014566   0.003740  -3.895\nreddsperkm_lag4:streamPrice                    -0.016379   0.004442  -3.687\nreddsperkm_lag4:streamSnake River Side Channel -0.015236   0.004466  -3.411\nreddsperkm_lag4:streamSpring                   -0.010905   0.004186  -2.605\nreddsperkm_lag4:streamUpper Bar BC              0.004217   0.002015   2.093\nreddsperkm_lag4:streamLower Bar BC              0.005705   0.001978   2.884\n                                               Pr(&gt;|t|)    \n(Intercept)                                     &lt; 2e-16 ***\nreddsperkm_lag4                                4.79e-09 ***\nreddsperkm_lag4:streamBlacktail                8.32e-06 ***\nreddsperkm_lag4:streamBlue Crane               2.05e-09 ***\nreddsperkm_lag4:streamCowboy Cabin             0.006262 ** \nreddsperkm_lag4:streamFish                     0.007895 ** \nreddsperkm_lag4:streamFlat                     3.25e-07 ***\nreddsperkm_lag4:streamLittle Bar BC            8.58e-07 ***\nreddsperkm_lag4:streamNowlin                   0.000126 ***\nreddsperkm_lag4:streamPrice                    0.000277 ***\nreddsperkm_lag4:streamSnake River Side Channel 0.000751 ***\nreddsperkm_lag4:streamSpring                   0.009720 ** \nreddsperkm_lag4:streamUpper Bar BC             0.037376 *  \nreddsperkm_lag4:streamLower Bar BC             0.004260 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6103 on 255 degrees of freedom\n  (189 observations deleted due to missingness)\nMultiple R-squared:  0.3973,    Adjusted R-squared:  0.3666 \nF-statistic: 12.93 on 13 and 255 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Modeling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Stock-Recruitment Analysis</span>"
    ]
  },
  {
    "objectID": "ReddCountsRicker.html#format-fish-data",
    "href": "ReddCountsRicker.html#format-fish-data",
    "title": "4  Stock-Recruitment Analysis",
    "section": "4.2 Format Fish Data",
    "text": "4.2 Format Fish Data\nLog annual redd count data and calculate number of years per population\n\n\nCode\n# log \ndat &lt;- dat %&gt;% mutate(rcraw_log = log(reddsperkm))\n\n# how many years of data does each pop have?\ndatatable(dat %&gt;% drop_na(rcraw_log) %&gt;% group_by(stream) %&gt;% summarize(nyr = n_distinct(rcraw_log)))\n\n\n\n\n\n\nFormat fish data into matrices for JAGS model\n\n\nCode\n# specify populations\npops &lt;- sort(unique(dat$stream))\nn.pops &lt;- length(pops)\n\n# specify years\nn.years &lt;- vector(length = n.pops)\nyears &lt;- matrix(nrow = n.pops, ncol = 51)\nfor(p in 1:n.pops) {\n  n.years[p] &lt;- length(unique(dat$year[dat$stream == pops[p]]))\n  years[p,1:n.years[p]] &lt;- sort(unique(dat$year[dat$stream == pops[p]]))\n}\n\n# Spawners and Recruits\nrec_raw &lt;- matrix(nrow = n.pops, ncol = max(n.years)) \n# rec_cor &lt;- matrix(nrow = n.pops, ncol = max(n.years))\n# rec_cor_sd &lt;- matrix(nrow = n.pops, ncol = max(n.years))\nfor(p in 1:n.pops) {\n  for(y in 1:n.years[p]) {\n    year &lt;- years[p,y]\n    rec_raw[p,y] &lt;- dat$rcraw_log[dat$stream == pops[p] & dat$year == year] # Raw, uncorrected ecruits (log scale)\n    # rec_cor[p,y] &lt;- dat$rccor_log_mean[dat$stream == pops[p] & dat$year == year] # Corrected recruits (log scale)\n    # rec_cor_sd[p,y] &lt;- dat$rccor_log_sd[dat$stream == pops[p] & dat$year == year] # recruitment uncertainty\n  }#next y\n}#next p\n\n\nGet maximum spawners for initialization\n\n\nCode\nmaxY &lt;- apply(exp(rec_raw), 1, max, na.rm = TRUE)\nmeanY &lt;- apply(exp(rec_raw), 1, mean, na.rm = TRUE)\n\n\nCheck dimensions\n\n\nCode\ndim(years)\n\n\n[1] 13 51\n\n\nCode\ndim(rec_raw)\n\n\n[1] 13 51\n\n\nCode\n# dim(rec_cor)\n# dim(rec_cor_sd)",
    "crumbs": [
      "Modeling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Stock-Recruitment Analysis</span>"
    ]
  },
  {
    "objectID": "ReddCountsRicker.html#format-covariate-data",
    "href": "ReddCountsRicker.html#format-covariate-data",
    "title": "4  Stock-Recruitment Analysis",
    "section": "4.3 Format Covariate Data",
    "text": "4.3 Format Covariate Data\nFor age apportionment model (split covariate effects among ages 0 and 1), set up two arrays of covariates: one for covariates lagged to reflect conditions during age-0 (4 years) and another for covariates lagged to reflect conditions during age-1 (3 years)\nGet covariate names\n\n\nCode\n# names.covars1 &lt;- grep(\"z\", names(dat0), value = TRUE)[c(1:3,5:8,11,14:19)] # age-0\n# names.covars0 &lt;- grep(\"z\", names(dat0), value = TRUE)[c(1:3,5:8,14:15,20,16:19)] # age-0\n# names.covars0 &lt;- grep(\"z\", names(dat0), value = TRUE)[c(1:3,5:8,20,14:19)] # age-0\nnames.covars0 &lt;- grep(\"z\", names(dat0), value = TRUE)[c(1:2,6,7:9,15:20)]#[c(2:3,5,7:9,15:20)] # age-0\n# names.covars2 &lt;- grep(\"z\", names(dat1), value = TRUE)[c(1:3,5:8,11,14:19)] # age-1\n# names.covars1 &lt;- grep(\"z\", names(dat0), value = TRUE)[c(1:3,5:8,14:15,20,16:19)] # age-1\n# names.covars1 &lt;- grep(\"z\", names(dat0), value = TRUE)[c(1:3,5:8,20,14:19)] # age-1\nnames.covars1 &lt;- grep(\"z\", names(dat1), value = TRUE)[c(1:2,6,7:9,15:20)]#[c(2:3,5,7:9,15:20)] # age-1\n\nprint(names.covars1)\n\n\n [1] \"z_jld_rampdur\"        \"z_jld_rampratemindoy\" \"z_jld_winvar\"        \n [4] \"z_jld_summean\"        \"z_jld_peakmag\"        \"z_jld_peaktime\"      \n [7] \"z_natq_peakmag\"       \"z_natq_peaktime\"      \"z_temp_falmean\"      \n[10] \"z_temp_winmean\"       \"z_temp_sprmean\"       \"z_temp_summean\"      \n\n\nFormat covariate data into matrices for JAGS model\n\n\nCode\nn.covars &lt;- length(names.covars0)\ncovars0 &lt;- array(data = NA, dim = c(n.pops, max(n.years), n.covars))\ncovars1 &lt;- array(data = NA, dim = c(n.pops, max(n.years), n.covars))\nfor(p in 1:n.pops) {\n  for(y in 1:n.years[p]) {\n    yr &lt;- years[p,y]\n    for(c in 1:n.covars) {\n      covars0[p,y,c] &lt;- as.numeric(dat0 %&gt;% select(stream, year, names.covars0[c]) %&gt;% filter(stream == pops[p] & year == yr) %&gt;% select(3))\n      covars1[p,y,c] &lt;- as.numeric(dat1 %&gt;% select(stream, year, names.covars1[c]) %&gt;% filter(stream == pops[p] & year == yr) %&gt;% select(3))\n    } # next c\n  } # next y\n  #print(p)\n} # next p\ndim(covars0)\n\n\n[1] 13 51 12\n\n\nCode\ndim(covars1)\n\n\n[1] 13 51 12\n\n\nAdd interaction and/or squared terms, if applicable\n\n\nCode\n# names.covars0 &lt;- c(names.covars0, \"z_int_peaktime\", \"z_int_peakmag\") # add names for additional terms\n# names.covars1 &lt;- c(names.covars1, \"z_int_peaktime\", \"z_int_peakmag\") # add names for additional terms\n# covars0 &lt;- abind::abind(covars0, covars0[,,6]*covars0[,,9], covars0[,,5]*covars0[,,8], along = 3)\n# covars1 &lt;- abind::abind(covars1, covars1[,,6]*covars1[,,9], covars1[,,5]*covars1[,,8], along = 3)\n# n.covars &lt;- length(names.covars0)\n\nnames.covars0 &lt;- c(names.covars0, \"z_int_peakmag\", \"z_int_peaktime\") # add names for additional terms\nnames.covars1 &lt;- c(names.covars1, \"z_int_peakmag\", \"z_int_peaktime\") # add names for additional terms\ncovars0 &lt;- abind::abind(covars0, covars0[,,5]*covars0[,,7], covars0[,,6]*covars0[,,8], along = 3)\ncovars1 &lt;- abind::abind(covars1, covars1[,,5]*covars1[,,7], covars0[,,6]*covars0[,,8], along = 3)\nn.covars &lt;- length(names.covars0)\n\n\n\n\nCode\n# OLD - NOT USED\n# # set up covariate array\n# names.covars &lt;- grep(\"z\", names(dat), value = TRUE)[c(1:8,11,14:19)] # for separated flow components\n# names.covars &lt;- grep(\"z\", names(dat), value = TRUE)[c(1:5,7:12)] # for experienced flow\n# names.covars &lt;- grep(\"z\", names(dat), value = TRUE)[c(1:3,5:8,11,14:19)]\n# names.covars &lt;- grep(\"z\", names(dat), value = TRUE)[c(1:3,14:19)]\n# \n# \n# n.covars &lt;- length(names.covars)\n# covars &lt;- array(data = NA, dim = c(n.pops, max(n.years), n.covars))\n# for(p in 1:n.pops) {\n#   for(y in 1:n.years[p]) {\n#     yr &lt;- years[p,y]\n#     for(c in 1:n.covars) {\n#       covars[p,y,c] &lt;- as.numeric(dat %&gt;% select(stream, year, names.covars[c]) %&gt;% filter(stream == pops[p] & year == yr) %&gt;% select(3))\n#     } # next c\n#   } # next y\n#   print(p)\n# } # next p\n# dim(covars)\n# \n# # (for separate flow components) Full interaction model: add array slices for squared terms, interaction terms\n# names.covars &lt;- c(names.covars, \"z_int_peakmag\", \"z_int_peaktime\", \"z_int_winmeanflow\", \"z_int_jldwinmeanvar\") # add names for additional terms\n# covars &lt;- abind::abind(covars, covars[,,7]*covars[,,10], covars[,,8]*covars[,,11], covars[,,4]*covars[,,9], covars[,,4]*covars[,,5], along = 3)\n# n.covars &lt;- length(names.covars)\n# \n# # (for experienced flow) Full interaction model: add array slices for squared terms, interaction terms\n# names.covars &lt;- c(names.covars, \"z_int_winflowmeanvar\", \"z_int_peakmagtime\") # add names for additional terms\n# covars &lt;- abind::abind(covars, covars[,,4]*covars[,,5], covars[,,6]*covars[,,7], along = 3)\n# n.covars &lt;- length(names.covars)\n# \n# names.covars &lt;- c(names.covars, \"z_int_peakmag\", \"z_int_peaktime\", \"z_int_winmeanvar\") # add names for additional terms\n# covars &lt;- abind::abind(covars, covars[,,5]*covars[,,7], covars[,,6]*covars[,,8], covars[,,13]*covars[,,14], along = 3)\n# n.covars &lt;- length(names.covars)\n# \n# # check dimensions\n# dim(covars)\n# \n# # create matrix for pre/post 1989\n# regime &lt;- matrix(data = NA, nrow = nrow(years), ncol = ncol(years))\n# for (i in 1:nrow(regime)) { for (j in 1:ncol(regime)) { regime[i,j] &lt;- ifelse(years[i,j] &lt; 1989, 0, 1) }}\n# # names.covars &lt;- c(names.covars, \"regime\")\n# # covars &lt;- abind::abind(covars, regime, along = 3)\n# # n.covars &lt;- length(names.covars)\n\n# plot(covars1[,,1] ~ covars2[,,1])\n# plot(covars1[,,2] ~ covars2[,,2])\n# plot(covars1[,,3] ~ covars2[,,3])\n# plot(covars1[,,4] ~ covars2[,,4])\n# plot(covars1[,,5] ~ covars2[,,5])\n# plot(covars1[,,6] ~ covars2[,,6])\n# plot(covars1[,,7] ~ covars2[,,7])\n# plot(covars1[,,8] ~ covars2[,,8])\n# plot(covars1[,,9] ~ covars2[,,9])\n# plot(covars1[,,10] ~ covars2[,,10])\n# plot(covars1[,,11] ~ covars2[,,11])\n# plot(covars1[,,12] ~ covars2[,,12])\n# plot(covars1[,,13] ~ covars2[,,13])\n# plot(covars1[,,14] ~ covars2[,,14])\n\n\nAdd empty columns for model initialization\n\n\nCode\n# recruitment\nrec_raw &lt;- cbind(matrix(NA, nrow = nrow(rec_raw), ncol = 4), rec_raw)\n# rec_cor &lt;- cbind(matrix(NA, nrow = nrow(rec_cor), ncol = 4), rec_cor)\n# rec_cor_sd &lt;- cbind(matrix(NA, nrow = nrow(rec_cor_sd), ncol = 4), rec_cor_sd)\n\n# covariates\n# rl &lt;- list()\n# for (i in 1:dim(covars)[3]) { rl[[i]] &lt;- cbind(matrix(NA, nrow = nrow(covars), ncol = 4), covars[,,i]) }\n# covars &lt;- abind::abind(rl, along = 3)\nrl &lt;- list()\nfor (i in 1:dim(covars0)[3]) { rl[[i]] &lt;- cbind(matrix(NA, nrow = nrow(covars0), ncol = 4), covars0[,,i]) }\ncovars0 &lt;- abind::abind(rl, along = 3)\nrl &lt;- list()\nfor (i in 1:dim(covars1)[3]) { rl[[i]] &lt;- cbind(matrix(NA, nrow = nrow(covars1), ncol = 4), covars1[,,i]) }\ncovars1 &lt;- abind::abind(rl, along = 3)\n\n# years\nn.years &lt;- n.years + 4\n\n# regime\n# regime &lt;- cbind(matrix(NA, nrow = nrow(regime), ncol = 4), regime)\n\n\nCheck dimensions\n\n\nCode\n# check dimensions\ndim(rec_raw)\n\n\n[1] 13 55\n\n\nCode\n# dim(rec_cor)\n# dim(rec_cor_sd)\n# dim(covars)\ndim(covars0)\n\n\n[1] 13 55 14\n\n\nCode\ndim(covars1)\n\n\n[1] 13 55 14\n\n\nCode\nmax(n.years)\n\n\n[1] 55",
    "crumbs": [
      "Modeling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Stock-Recruitment Analysis</span>"
    ]
  },
  {
    "objectID": "ReddCountsRicker.html#model-in-jags",
    "href": "ReddCountsRicker.html#model-in-jags",
    "title": "4  Stock-Recruitment Analysis",
    "section": "4.4 Model in JAGS",
    "text": "4.4 Model in JAGS\n\n4.4.1 Specify JAGS model\nState-space hierarchical Ricker stock-recruitment model with auto-correlated residuals, where observation error is an estimated parameter. Covariates can affect productivity at either age-0 or age-1, with a parameter that estimates the relative importance of effects at each age class. Observations are distributed log-normally around (latent, phases 1-2) redd densities. Log-log scale ensures positive values and allows sigma.oe to be estimated on a log-scale and directly compared to net error model estimates of redd count error from Baldock et al. (2023 CJFAS): 0.38 (mean and 95% CI = 0.34, 0.44)\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\n# OBSERVATION PROCESS\nfor (j in 1:numPops) {\n    for (i in 1:numYears[j]) {\n        logY0[j,i] ~ dnorm(logY[j,i], pow(sigma.oe, -2)) \n        N[j,i] &lt;- exp(logY[j,i])\n        }\n    }\n\n# STATE PROCESS\nfor (j in 1:numPops) {\n\n    # STARTING VALUES / INITIALIZATION\n    Y1[j] ~ dunif(1, maxY[j])\n    Y2[j] ~ dunif(1, maxY[j])\n    Y3[j] ~ dunif(1, maxY[j])\n    Y4[j] ~ dunif(1, maxY[j])\n    logY[j,1] &lt;- log(Y1[j])\n    logY[j,2] &lt;- log(Y2[j])\n    logY[j,3] &lt;- log(Y3[j])\n    logY[j,4] &lt;- log(Y4[j])\n\n    logresid[j,4] &lt;- 0\n\n    # ALL OTHER YEARS\n    for (i in 5:numYears[j]) {\n\n        # Derive population and year specific covariate effects \n        for (c in 1:numCovars) { \n            covars0[j,i,c] ~ dnorm(0, pow(1, -2))\n            covars1[j,i,c] ~ dnorm(0, pow(1, -2))\n            cov.eff[j,i,c] &lt;- coef[j,c] * (((1-p[c]) * covars0[j,i,c]) + (p[c] * covars1[j,i,c])) }\n        \n        # Likelihood and predictions\n        logY[j,i] ~ dnorm(logpred2[j,i], pow(sigma.pe[j], -2))\n        logpred[j,i] &lt;- logY[j,i-4] + A[j] - B[j] * exp(logY[j,i-4]) + sum(cov.eff[j,i,1:numCovars])\n        \n        # save observations and latent states in loop to exclude starting values from model object\n        loglatent[j,i] &lt;- logY[j,i]\n        logobserv[j,i] &lt;- logY0[j,i]\n        \n        # Auto-correlated residuals\n        logresid[j,i] &lt;- logY[j,i] - logpred[j,i]\n        logpred2[j,i] &lt;- logpred[j,i] + logresid[j,i-1] * phi[j]\n        logresid2[j,i] &lt;- logY[j,i] - logpred2[j,i]\n        \n        # Log-likelihood\n        loglik[j,i] &lt;- logdensity.norm(logY0[j,i], logY[j,i], pow(sigma.oe, -2))\n        }\n    }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Observation error is shared among populations, constrained prior...consider centering this on Baldock et al (2023) CJFAS estimate\nsigma.oe ~ dunif(0.001, 100) #dnorm(0, pow(0.5, -2)) T(0,)\n\n# Population-specific parameters\nfor (j in 1:numPops) {\n\n    # Ricker A\n    #expA[j] ~ dunif(0, 20)\n    #A[j] &lt;- log(expA[j])\n    A[j] ~ dnorm(mu.A, pow(sigma.A, -2)) \n\n    # Ricker B\n    B[j] ~ dnorm(0, pow(1, -2)) T(0,)\n    #B[j] ~ dnorm(mu.B, pow(sigma.B, -2))\n\n    # Covariate effects\n    for (c in 1:numCovars) { coef[j,c] ~ dnorm(mu.coef[c], pow(sigma.coef[c], -2)) }\n\n    # Process error\n    sigma.pe[j] ~ dunif(0.001, 100) #dnorm(0, pow(5, -2)) T(0,)\n\n    # auto-correlated residuals\n    phi[j] ~ dunif(-0.99, 0.99)\n\n    }\n\n# Global Ricker A and B\nmu.A &lt;- log(exp.mu.A) #dunif(0, 20)\nexp.mu.A ~ dunif(0, 20)\nsigma.A ~ dunif(0.001, 100)\n#mu.B ~ dnorm(0, pow(1, -2)) T(0,)\n#sigma.B ~ dunif(0.001, 100)\n\n# Global covariate effects\nfor (c in 1:numCovars) { \n    mu.coef[c] ~ dnorm(0, pow(25, -2)) \n    sigma.coef[c] ~ dunif(0.001, 100) #dnorm(0, pow(5, -2)) T(0.001,100)\n    p[c] ~ dunif(0, 1)\n    }\n\n\n##--- DERIVED QUANTITIES ---------------------------------------------##\n\n# Population specific carrying capacity\nfor (j in 1:numPops) { K[j] &lt;- A[j] / B[j] }\n\n}\", file = \"JAGS Models/Ricker_Hierarchical_StateSpace_OEestimated_Covars_Proportional.txt\")\n\n\nSame as above, but covariates only affect productivity at age-0\n\n\nCode\ncat(\"model {\n\n##--- LIKELIHOOD ---------------------------------------------------##\n\n# OBSERVATION PROCESS\nfor (j in 1:numPops) {\n    for (i in 1:numYears[j]) {\n        logY0[j,i] ~ dnorm(logY[j,i], pow(sigma.oe, -2)) \n        N[j,i] &lt;- exp(logY[j,i])\n        }\n    }\n\n# STATE PROCESS\nfor (j in 1:numPops) {\n\n    # STARTING VALUES / INITIALIZATION\n    Y1[j] ~ dunif(1, maxY[j])\n    Y2[j] ~ dunif(1, maxY[j])\n    Y3[j] ~ dunif(1, maxY[j])\n    Y4[j] ~ dunif(1, maxY[j])\n    logY[j,1] &lt;- log(Y1[j])\n    logY[j,2] &lt;- log(Y2[j])\n    logY[j,3] &lt;- log(Y3[j])\n    logY[j,4] &lt;- log(Y4[j])\n\n    logresid[j,4] &lt;- 0\n\n    # ALL OTHER YEARS\n    for (i in 5:numYears[j]) {\n\n        # Derive population and year specific covariate effects \n        for (c in 1:numCovars) { \n            covars[j,i,c] ~ dnorm(0, pow(1, -2))\n            cov.eff[j,i,c] &lt;- coef[j,c] * covars[j,i,c] }\n        \n        # Likelihood and predictions\n        logY[j,i] ~ dnorm(logpred2[j,i], pow(sigma.pe[j], -2))\n        logpred[j,i] &lt;- logY[j,i-4] + A[j] - B[j] * exp(logY[j,i-4]) + sum(cov.eff[j,i,1:numCovars])\n                \n        # save observations and latent states in loop to exclude starting values from model object\n        loglatent[j,i] &lt;- logY[j,i]\n        logobserv[j,i] &lt;- logY0[j,i]\n        \n        # Auto-correlated residuals\n        logresid[j,i] &lt;- logY[j,i] - logpred[j,i]\n        logpred2[j,i] &lt;- logpred[j,i] + logresid[j,i-1] * phi[j]\n        logresid2[j,i] &lt;- logY[j,i] - logpred2[j,i]\n        \n        # Log-likelihood\n        loglik[j,i] &lt;- logdensity.norm(logY0[j,i], logY[j,i], pow(sigma.oe, -2))\n        }\n    }\n\n\n##--- PRIORS --------------------------------------------------------##\n\n# Observation error is shared among populations, constrained prior...consider centering this on Baldock et al (2023) CJFAS estimate\nsigma.oe ~ dunif(0.001, 100) #dnorm(0, pow(0.5, -2)) T(0,)\n\n# Population-specific parameters\nfor (j in 1:numPops) {\n\n    # Ricker A\n    #expA[j] ~ dunif(0, 20)\n    #A[j] &lt;- log(expA[j])\n    A[j] ~ dnorm(mu.A, pow(sigma.A, -2)) \n\n    # Ricker B\n    B[j] ~ dnorm(0, pow(1, -2)) T(0,)\n    #B[j] ~ dnorm(mu.B, pow(sigma.B, -2))\n\n    # Covariate effects\n    for (c in 1:numCovars) { coef[j,c] ~ dnorm(mu.coef[c], pow(sigma.coef[c], -2)) }\n\n    # Process error\n    sigma.pe[j] ~ dunif(0.001, 100) #dnorm(0, pow(5, -2)) T(0,)\n\n    # auto-correlated residuals\n    phi[j] ~ dunif(-0.99, 0.99)\n\n    }\n\n# Global Ricker A and B\nmu.A &lt;- log(exp.mu.A) #dunif(0, 20)\nexp.mu.A ~ dunif(0, 20)\nsigma.A ~ dunif(0.001, 100)\n#mu.B ~ dnorm(0, pow(1, -2)) T(0,)\n#sigma.B ~ dunif(0.001, 100)\n\n# Global covariate effects\nfor (c in 1:numCovars) { \n    mu.coef[c] ~ dnorm(0, pow(25, -2)) \n    sigma.coef[c] ~ dunif(0.001, 100) #dnorm(0, pow(5, -2)) T(0.001,100)\n    }\n\n\n##--- DERIVED QUANTITIES ---------------------------------------------##\n\n# Population specific carrying capacity\nfor (j in 1:numPops) { K[j] &lt;- A[j] / B[j] }\n\n}\", file = \"JAGS Models/Ricker_Hierarchical_StateSpace_OEestimated_Covars.txt\")\n\n\n\n\n4.4.2 Age-0/1 Proportional\nParameters to monitor\n\n\nCode\njags.params &lt;- c(\"A\", \"B\", \"K\", \"mu.A\", \"sigma.A\", \"sigma.oe\", \"sigma.pe\",   # Ricker parameters\n                 \"coef\", \"mu.coef\", \"sigma.coef\", \"cov.eff\", \"p\",            # covariate effects\n                 \"logpred\", \"logpred2\",                                      # predictions\n                 \"loglatent\", \"logobserv\",                                   # latent states and observations\n                 \"phi\", \"logresid\", \"logresid2\", \"loglik\")                   # AR1 term, residuals, log-likelihood\n\n\nRun model in JAGS\n\n\nCode\nst &lt;- Sys.time()\njags.data &lt;- list(\"logY0\" = rec_raw, \"numYears\" = n.years, \"numPops\" = n.pops, \"maxY\" = maxY, \"covars0\" = covars0, \"covars1\" = covars1, \"numCovars\" = n.covars)\nmod_01pb &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params, \n                          model.file = \"JAGS Models/Ricker_Hierarchical_StateSpace_OEestimated_Covars_Proportional.txt\", \n                          n.chains = 20, n.thin = 200, n.burnin = 10000, n.iter = 60000, DIC = TRUE)\nMCMCtrace(mod_01pb, ind = TRUE, params = c(\"A\", \"B\", \"mu.A\", \"sigma.A\", \"sigma.oe\", \"sigma.pe\", \"mu.coef\", \"sigma.coef\", \"p\", \"phi\"),\n          filename = \"Model output/MCMCtrace_ReddCountsRicker_Test_Age01p_winvar.pdf\") # write out traceplots\nSys.time() - st\nbeep()\n\n\nSave model output as RDS file\n\n\nCode\nsaveRDS(mod_01pb, \"Model output/ReddCountsRicker_Phase1_Age01p_winvar.RDS\")\n\n\nRead in model RDS file\n\n\nCode\nmod_01pb &lt;- readRDS(\"Model output/ReddCountsRicker_Phase1_Age01p_winvar.RDS\")\n\n\nCheck R-hat values\n\n\nCode\nmod_01pb$BUGSoutput$summary[,8][mod_01pb$BUGSoutput$summary[,8] &gt; 1.05]\n\n\n  K[11] \n1.28153 \n\n\n\n\n4.4.3 Age-0 only\nNOT CURRENTLY USED\nParameters to monitor\n\n\nCode\njags.params &lt;- c(\"A\", \"B\", \"K\", \"mu.A\", \"sigma.A\", \"sigma.oe\", \"sigma.pe\",   # Ricker parameters\n                 \"coef\", \"mu.coef\", \"sigma.coef\", \"cov.eff\",            # covariate effects\n                 \"logpred\", \"logpred2\",                                      # predictions\n                 \"loglatent\", \"logobserv\",                                   # latent states and observations\n                 \"phi\", \"logresid\", \"logresid2\", \"loglik\")                   # AR1 term, residuals, log-likelihood\n\n\nRun model in JAGS\n\n\nCode\nst &lt;- Sys.time()\njags.data &lt;- list(\"logY0\" = rec_raw, \"numYears\" = n.years, \"numPops\" = n.pops, \"maxY\" = maxY, \"covars\" = covars0, \"numCovars\" = n.covars)\nmod_0 &lt;- jags.parallel(data = jags.data, inits = NULL, parameters.to.save = jags.params, \n                          model.file = \"JAGS Models/Ricker_Hierarchical_StateSpace_OEestimated_Covars.txt\", \n                          n.chains = 20, n.thin = 200, n.burnin = 10000, n.iter = 40000, DIC = TRUE)\nMCMCtrace(mod_0, ind = TRUE, params = c(\"A\", \"B\", \"mu.A\", \"sigma.A\", \"sigma.oe\", \"sigma.pe\", \"mu.coef\", \"sigma.coef\", \"p\", \"phi\"),\n          filename = \"Model output/MCMCtrace_ReddCountsRicker_Test_Age0.pdf\") # write out traceplots\nSys.time() - st\nbeep()\n\n\nCheck R-hat values\n\n\nCode\nmod_0$BUGSoutput$summary[,8][mod_0$BUGSoutput$summary[,8] &gt; 1.05]\n\n\nSave model output as RDS file\n\n\nCode\nsaveRDS(mod_0, \"Model output/ReddCountsRicker_Phase1_Age0.RDS\")\n\n\nRead in model RDS file\n\n\nCode\nmod_0 &lt;- readRDS(\"Redd Counts Ricker/Model output/ReddCountsRicker_Phase1_Age0.RDS\")\n\n\n\n\n4.4.4 LOO-CV\n\n\nCode\nll.arr &lt;- mod_01pb$BUGSoutput$sims.list$loglik # extract the log-likelihood estimates for each MCMC sample\nll.mat &lt;- ll.arr[,,1]\nfor (j in 2:dim(ll.arr)[3]) {\n  ll.mat &lt;- cbind(ll.mat, ll.arr[,,j])\n}\nrf &lt;- relative_eff(exp(ll.mat), chain_id = rep(1:20, each = 250))\nmy_loo &lt;- loo(ll.mat, r_eff = rf)\nplot(my_loo)\n\n\n\n\n\n\n\n\n\n\n\n4.4.5 Set top model\nSet top model and save MCMC samples and parameter summary\n\n\nCode\ntopmod &lt;- mod_01pb\n\n# generate MCMC samples and store as an array\nmodelout &lt;- topmod$BUGSoutput\nparam.summary &lt;- modelout$summary\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) {\n  McmcList[[i]] = as.mcmc(modelout$sims.array[,i,])\n}\n# rbind MCMC samples from 3 chains \nMcmcdat &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]])\nparam.summary &lt;- as.data.frame(modelout$summary)\n\n# save model output\nwrite_csv(as.data.frame(Mcmcdat), \"Model output/ReddCountsRicker_Phase1_Age01p_mcmcsamps.csv\")\nwrite.csv(as.data.frame(modelout$summary), \"Model output/ReddCountsRicker_Phase1_Age01p_ParameterSummary.csv\", row.names = T)",
    "crumbs": [
      "Modeling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Stock-Recruitment Analysis</span>"
    ]
  },
  {
    "objectID": "ReddCountsRicker.html#model-diagnostics",
    "href": "ReddCountsRicker.html#model-diagnostics",
    "title": "4  Stock-Recruitment Analysis",
    "section": "4.5 Model Diagnostics",
    "text": "4.5 Model Diagnostics\nGet expected and observed MCMC samples\n\n\nCode\nppdat_exp &lt;- as.matrix(Mcmcdat[,startsWith(colnames(Mcmcdat), \"logpred2\")])\nppdat_obs &lt;- as.matrix(Mcmcdat[,startsWith(colnames(Mcmcdat), \"loglatent\")])\n\n\n\n4.5.1 Residuals\nHistogram of residuals\n\n\nCode\npar(mar = c(4,4,1,1), mgp = c(2.5,1,0))\nhist((ppdat_obs - ppdat_exp), main = \"\", xlab = \"Observed - Expected\")\nlegend(\"topright\", bty = \"n\", legend = paste(\"Median Resid. = \", round(median((ppdat_obs - ppdat_exp)), digits = 4), sep = \"\"))\nabline(v = median(unlist(ppdat_obs - ppdat_exp)), col = \"red\", lwd = 2)\nbox(bty = \"o\")\n\n\n\n\n\n\n\n\n\n\n4.5.1.1 Before autocorrelation\n\n\nCode\nlogresid &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\nfor (j in 1:nrow(rec_raw)) {\n  for (i in 1:ncol(rec_raw)+4) {\n    try(logresid[j,i] &lt;- param.summary[paste(\"logresid[\",j,\",\",i,\"]\", sep = \"\"),1])\n  }\n}\n\n\nTime series of residuals (AR1)\n\n\nCode\npar(mfrow = c(4,4), mgp = c(2,0.8,0), mar = c(2.5, 3, 1.5, 0.5))\nfor (i in 1:n.pops) {\n  plot(logresid[i,c(5:55)] ~ years[i,c(1:51)], pch = 16, xlab = \"\", ylab = \"log residuals\", main = pops[i], xlim = c(1970, 2021), ylim = c(min(logresid, na.rm = T), max(logresid, na.rm = T)))\n  lines(logresid[i,c(5:55)] ~ years[i,c(1:51)])\n  abline(h = 0, lty = 2)\n}\n\n\n\n\n\n\n\n\n\ntime series of residuals (AR1), unique y scale\n\n\nCode\npar(mfrow = c(4,4), mgp = c(2,0.8,0), mar = c(2.5, 3, 1.5, 0.5))\nfor (i in 1:n.pops) {\n  plot(logresid[i,c(5:55)] ~ years[i,c(1:51)], pch = 16, xlab = \"\", ylab = \"log residuals\", main = pops[i], xlim = c(1970, 2021))\n  lines(logresid[i,c(5:55)] ~ years[i,c(1:51)])\n  abline(h = 0, lty = 2)\n}\n\n\n\n\n\n\n\n\n\n\n\n4.5.1.2 After autocorrelation\nResiduals AFTER accounting for autocorrelation sensu Murdoch et al 2024 CJFAS\n\n\nCode\nlogresid &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\nfor (j in 1:nrow(rec_raw)) {\n  for (i in 1:ncol(rec_raw)+4) {\n    try(logresid[j,i] &lt;- param.summary[paste(\"logresid2[\",j,\",\",i,\"]\", sep = \"\"),1])\n  }\n}\n\n\ntime series of residuals (AR1)\n\n\nCode\npar(mfrow = c(4,4), mgp = c(2,0.8,0), mar = c(2.5, 3, 1.5, 0.5))\nfor (i in 1:n.pops) {\n  plot(logresid[i,c(5:55)] ~ years[i,c(1:51)], pch = 16, xlab = \"\", ylab = \"log residuals\", main = pops[i], xlim = c(1970, 2021), ylim = c(min(logresid, na.rm = T), max(logresid, na.rm = T)))\n  lines(logresid[i,c(5:55)] ~ years[i,c(1:51)])\n  abline(h = 0, lty = 2)\n}\n\n\n\n\n\n\n\n\n\ntime series of residuals (AR1), unique y scale\n\n\nCode\npar(mfrow = c(4,4), mgp = c(2,0.8,0), mar = c(2.5, 3, 1.5, 0.5))\nfor (i in 1:n.pops) {\n  plot(logresid[i,c(5:55)] ~ years[i,c(1:51)], pch = 16, xlab = \"\", ylab = \"log residuals\", main = pops[i], xlim = c(1970, 2021))\n  lines(logresid[i,c(5:55)] ~ years[i,c(1:51)])\n  abline(h = 0, lty = 2)\n}\n\n\n\n\n\n\n\n\n\nShow residual autocorrelation plots by population\n\n\nCode\npar(mfrow = c(4,4), mgp = c(2,0.8,0), mar = c(3, 3, 0.5, 0.5))\nfor (i in 1:n.pops) {\n  pacf(logresid[i,][complete.cases(logresid[i,])], main = pops[i])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.2 Bayesian p-value\n\n\nCode\n# Bayesian p-value\nsum(ppdat_exp &gt; ppdat_obs) / (dim(ppdat_obs)[1]*dim(ppdat_obs)[2])\n\n\n[1] 0.4857758\n\n\n\n\n4.5.3 PP Check\nNote that this isn’t a posterior predictive check in the true sense, but rather a comparison between the model-estimated latent states (log redd density) and the model predicted means.\n\n\nCode\npar(mar = c(4,4,1,1), mgp = c(2.5,1,0))\nplot(x = seq(from = 1.5, to = 6.5, length.out = 100), y = seq(from = 1.5, to = 6.5, length.out = 100), pch = NA, xlab = \"Latent ln(recruitment)\", ylab = \"Median posterior expected ln(recruitment)\")\npoints(apply(ppdat_exp, 2, median, na.rm = T) ~ apply(ppdat_obs, 2, median, na.rm = T))\nlegend(\"topleft\", bty = \"n\", legend = paste(\"Bayesian p-value = \", round(sum(ppdat_exp &gt; ppdat_obs) / (dim(ppdat_obs)[1]*dim(ppdat_obs)[2]), digits = 3), sep = \"\"))\nabline(a = 0, b = 1, col = \"red\", lwd = 2)",
    "crumbs": [
      "Modeling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Stock-Recruitment Analysis</span>"
    ]
  },
  {
    "objectID": "ReddCountsRicker.html#plot-model-output",
    "href": "ReddCountsRicker.html#plot-model-output",
    "title": "4  Stock-Recruitment Analysis",
    "section": "4.6 Plot Model Output",
    "text": "4.6 Plot Model Output\n\n4.6.1 Time series fits\nPull latent and predicted abundance from model output\n\n\nCode\n# set up matrices: latent states\nN_med &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\nN_low &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\nN_upp &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\n\n# set up matrices: predictions\nP_med &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\nP_low &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\nP_upp &lt;- matrix(data = NA, nrow = nrow(rec_raw), ncol = ncol(rec_raw)+4)\n\n# pull latent and predicted abundance from parameter summary\nfor (j in 1:nrow(rec_raw)) {\n  for (i in 1:ncol(rec_raw)+4) {\n    # try(N_med[j,i] &lt;- exp(param.summary[paste(\"loglatent[\",j,\",\",i,\"]\", sep = \"\"),5]))\n    # try(N_low[j,i] &lt;- exp(param.summary[paste(\"loglatent[\",j,\",\",i,\"]\", sep = \"\"),3]))\n    # try(N_upp[j,i] &lt;- exp(param.summary[paste(\"loglatent[\",j,\",\",i,\"]\", sep = \"\"),7]))\n    # \n    # try(P_med[j,i] &lt;- exp(param.summary[paste(\"logpred2[\",j,\",\",i,\"]\", sep = \"\"),5]))\n    # try(P_low[j,i] &lt;- exp(param.summary[paste(\"logpred2[\",j,\",\",i,\"]\", sep = \"\"),3]))\n    # try(P_upp[j,i] &lt;- exp(param.summary[paste(\"logpred2[\",j,\",\",i,\"]\", sep = \"\"),7]))\n\n    loglatent &lt;- NA\n    logpred2 &lt;- NA\n    \n    try(loglatent &lt;- Mcmcdat[,paste(\"loglatent[\",j,\",\",i,\"]\", sep = \"\")])\n    try(logpred2 &lt;- Mcmcdat[,paste(\"logpred2[\",j,\",\",i,\"]\", sep = \"\")])\n    \n    try(N_med[j,i] &lt;- quantile(exp(loglatent), prob = 0.50))\n    try(N_low[j,i] &lt;- quantile(exp(loglatent), prob = 0.05))\n    try(N_upp[j,i] &lt;- quantile(exp(loglatent), prob = 0.95))\n    \n    try(P_med[j,i] &lt;- quantile(exp(logpred2), prob = 0.50))\n    try(P_low[j,i] &lt;- quantile(exp(logpred2), prob = 0.05))\n    try(P_upp[j,i] &lt;- quantile(exp(logpred2), prob = 0.95))\n    \n  }\n}\n\n\nSet up and check color palette for color blindess accessibility\n\n\nCode\nrec &lt;- rec_raw\npopshort &lt;- c(\"THCH\", \"BLKT\", \"BLCR\", \"COCA\", \"FISH\", \"FLAT\", \"LTBC\", \"LOBC\", \"NOWL\", \"PRCE\", \"SRSC\", \"SPRG\", \"UPBC\")\nmycols &lt;- c(\"orchid1\", \"forestgreen\")# c(\"darkorange\", \"dodgerblue\") # hcl.colors(2, \"Red-Green\")\npalette_check(col2hcl(mycols), plot = TRUE)\n\n\n\n\n\n\n\n\n\n          name n tolerance ncp ndcp min_dist mean_dist max_dist\n1       normal 2  85.67993   1    1 85.67993  85.67993 85.67993\n2 deuteranopia 2  85.67993   1    0 50.06492  50.06492 50.06492\n3   protanopia 2  85.67993   1    0 55.64110  55.64110 55.64110\n4   tritanopia 2  85.67993   1    0 56.34705  56.34705 56.34705\n\n\nPlot time series data with observations, latent states, and model fits.\n\n\nCode\npar(mfrow = c(4,4), mgp = c(2,0.6,0), mar = c(1.2, 1.2, 2, 1.2), oma = c(2.5,2.5,0,0))\nfor (i in 1:n.pops) {\n  plot(exp(rec_raw[i,c(5:55)]) ~ years[i,c(1:51)], type = \"n\", xlab = \"\", ylab = \"\", xlim = c(1970, 2021), ylim = c(0, exp(max(rec_raw[i,], na.rm = T))))\n  title(popshort[i], line = 0.25)\n  # pop-specific years\n  yrpreds &lt;- as.numeric(na.omit(years[i,c(1:51)]))#[1:(length(as.numeric(na.omit(years[i,c(1:51)])))-4)]\n  # pop-specific latent states\n  nmedpreds &lt;- as.numeric(na.omit(N_med[i,c(5:55)]))\n  nlowpreds &lt;- as.numeric(na.omit(N_low[i,c(5:55)]))\n  nupppreds &lt;- as.numeric(na.omit(N_upp[i,c(5:55)]))\n  # pop-specific predictions\n  pmedpreds &lt;- as.numeric(na.omit(P_med[i,c(5:55)]))\n  plowpreds &lt;- as.numeric(na.omit(P_low[i,c(5:55)]))\n  pupppreds &lt;- as.numeric(na.omit(P_upp[i,c(5:55)]))\n  # carrying capacity\n  abline(h = param.summary[paste(\"K[\",i,\"]\", sep = \"\"),5], lty = 3)\n  # plot latent states\n  lines(nmedpreds ~ yrpreds, lwd = 1.5, col = mycols[1])\n  polygon(x = c(yrpreds, rev(yrpreds)), y = c(c(nlowpreds), rev(nupppreds)), col = scales::alpha(mycols[1], 0.3), border = NA)\n  # plot predictions\n  lines(pmedpreds ~ yrpreds, lwd = 1.5, col = mycols[2])\n  polygon(x = c(yrpreds, rev(yrpreds)), y = c(c(plowpreds), rev(pupppreds)), col = scales::alpha(mycols[2], 0.3), border = NA)\n  # plot observations\n  points(exp(rec_raw[i,c(5:55)]) ~ years[i,c(1:51)], pch = 1)\n  # legend\n  #legend(\"topright\", legend = pops[i], bty = \"n\", border = NA, col = NA, fill = NA, cex = 1.25)\n}\nmtext(\"Year\", side = 1, line = 1, outer = T)\nmtext(expression(\"Redds km\"^-1), side = 2, line = 1, outer = T)\nplot.new()\nlegend(\"center\", legend = c(\"Observations\", \"Latent states\", \"Predictions\"), pch = c(1,NA,NA), lwd = c(NA,2,2), col = c(\"black\", mycols[1], mycols[2]), bty = \"n\", cex = 1.5)\n\n\n\n\n\n\n\n\n\nPopulation summaries of latent states and carrying capacity, arranged from least to most variable (based on CV).\n\n\nCode\nmeans &lt;- apply(N_med, 1, mean, na.rm = T)\nsds &lt;- apply(N_med, 1, sd, na.rm = T)\ncvs &lt;- sds/means\nmins &lt;- apply(N_med, 1, min, na.rm = T)\nmaxs &lt;- apply(N_med, 1, max, na.rm = T)\nrelc &lt;- maxs/mins\nks &lt;- param.summary[grep(\"K\", row.names(param.summary), value = TRUE),5]\n\npoptib &lt;- tibble(pop = pops, mean = round(means, digits = 3), sd = round(sds, digits = 3), cv = round(cvs, digits = 3), min = round(mins, digits = 3), max = round(maxs, digits = 3), K = round(ks, digits = 3))\ndatatable(poptib %&gt;% arrange(cv))\n\n\n\n\n\n\n\n\n4.6.2 Parameter dot plots\nCoerce to ggs object\n\n\nCode\nmod.gg &lt;- ggs(as.mcmc(topmod), keep_original_order = TRUE)\npopshort &lt;- c(\"THCH\", \"BLKT\", \"BLCR\", \"COCA\", \"FISH\", \"FLAT\", \"LTBC\", \"LOBC\", \"NOWL\", \"PRCE\", \"SRSC\", \"SPRG\", \"UPBC\")\n\n\nRemind covariate names…\n\n\nCode\nnames.covars0\n\n\n [1] \"z_jld_rampdur\"        \"z_jld_rampratemindoy\" \"z_jld_winvar\"        \n [4] \"z_jld_summean\"        \"z_jld_peakmag\"        \"z_jld_peaktime\"      \n [7] \"z_natq_peakmag\"       \"z_natq_peaktime\"      \"z_temp_falmean\"      \n[10] \"z_temp_winmean\"       \"z_temp_sprmean\"       \"z_temp_summean\"      \n[13] \"z_int_peakmag\"        \"z_int_peaktime\"      \n\n\nCovariate types and pretty covariate names\n\n\nCode\nCovType &lt;- factor(c(rep(\"Managed flow\", times = 6), \n                    rep(\"Natural flow\", times = 2), \n                    rep(\"Temperature\", times = 4), \n                    rep(\"Interaction\", times = 2)),\n                  levels = c(\"Managed flow\", \"Natural flow\", \"Temperature\", \"Interaction\"))\n\n# rename covariates\nnames.covars.new &lt;- c(\"Duration of ramp down\", \"Timing of ramp down\", \n                      \"Mgd. winter flow var.\", \"Mgd. summer mean flow\", \"Mgd. peak flow mag.\", \"Mgd. peak flow timing\", \n                      \"Nat. peak flow mag.\", \"Nat. peak flow timing\",\n                      \"Autumn temperature\", \"Winter temperature\", \"Spring temperature\", \"Summer temperature\",\n                      \"Mgd. x Nat. peak flow mag.\", \"Mgd. x Nat. peak flow timing\")\n\n\nSet color palette\n\n\nCode\n# bls &lt;- hcl.colors(5, \"Blues3\")\n# mycols &lt;- c(\"darkorange\", bls[c(3,1)], \"seagreen\", \"grey50\")\nmycols &lt;- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#999999\")\n#palette_check(col2hcl(mycols), plot = TRUE)\n\n\n\n4.6.2.1 Global covariate effects\n\n\nCode\nggs_caterpillar(D = mod.gg, family = \"mu.coef\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n  theme_bw() + ylab(\"Environmental driver\") + xlab(\"Global change in productivity, ln(R/S)\") + aes(color = CovType) + scale_color_manual(values = mycols) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") + scale_y_discrete(labels = rev(names.covars.new), limits = rev) +\n  theme(legend.position = \"top\", legend.title = element_blank(), axis.text = element_text(color = \"black\"),\n        legend.key.spacing.y = unit(0, \"cm\"), legend.key.spacing.x = unit(1, \"cm\"), legend.margin = margin(0,0,0,0)) + \n  guides(color = guide_legend(nrow = 2, byrow = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.2 Population covariate effects\nDefine colors\n\n\nCode\nmycols2 &lt;- c(rep(mycols[1], times = 6), rep(mycols[2], times = 2), \n             rep(mycols[3], times = 4), rep(mycols[4], times = 2))\n\n\nGenerate plots in a for loop\n\n\nCode\n# generate plots in a for loop\nfor (i in 1:length(names.covars0)) {\n  jpeg(paste(\"Figures/Dot Plots/Pop Level Covariate Effects/ReddCounts_Ricker_CovarModel_DotPlot_Covs\", i, \"_\", names.covars0[i], \".jpg\", sep = \"\"), units = \"in\", width = 5, height = 5, res = 1500)\n  print(ggs_caterpillar(D = mod.gg %&gt;% filter(Parameter %in% paste(\"coef[\", 1:16, \",\", i, \"]\", sep = \"\")), family = \"coef\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n          theme_bw() + ylab(\"\") + xlab(\"Effect\") + ggtitle(names.covars.new[i]) + scale_y_discrete(labels = rev(pops), limits = rev) + geom_vline(xintercept = 0, linetype = \"dashed\") + \n          aes(color = CovType[i]) + scale_color_manual(values = mycols2[i]) + theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5), axis.text = element_text(color = \"black\")))\n  dev.off()\n}\n\n\nCombined plot\n\n\nCode\ncovplots &lt;- list()\npopshort &lt;- c(\"THCH\", \"BLKT\", \"BLCR\", \"COCA\", \"FISH\", \"FLAT\", \"LTBC\", \"LOBC\", \"NOWL\", \"PRCE\", \"SRSC\", \"SPRG\", \"UPBC\")\nfor (i in 1:length(names.covars0)) {\n  p1 &lt;- eval(substitute(ggs_caterpillar(D = mod.gg %&gt;% filter(Parameter %in% paste(\"coef[\", 1:16, \",\", i, \"]\", sep = \"\")), family = \"coef\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n                          theme_bw() + ylab(\"\") + xlab(\"\") + xlim(-0.55, 0.49) + ggtitle(names.covars.new[i]) + geom_vline(xintercept = 0, linetype = \"dashed\") + \n                          scale_y_discrete(labels = rev(popshort), limits = rev) + aes(color = CovType[i]) + scale_color_manual(values = mycols2[i]) + \n                          theme(legend.position = \"none\", plot.margin = unit(c(0.1,0.1,-0.7,-0.5), 'lines'), plot.title = element_text(vjust = -0.5, hjust = 0.5), axis.text = element_text(color = \"black\")), list(i = i)))\n  covplots[[i]] &lt;- p1\n}\nmyfig &lt;- ggarrange(plotlist = covplots, ncol = 4, nrow = 4)\nmyfig\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.3 Population variation in covariate effects\n\n\nCode\nggs_caterpillar(D = mod.gg, family = \"sigma.coef\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n  theme_bw() + ylab(\"Environmental driver\") + xlab(\"Population-level variation in covariate effect\") + aes(color = CovType) + scale_color_manual(values = mycols) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") + scale_y_discrete(labels = rev(names.covars.new), limits = rev) +\n  theme(legend.position = \"top\") + theme(legend.title = element_blank(), axis.text = element_text(color = \"black\"), \n        legend.key.spacing.y = unit(0, \"cm\"), legend.key.spacing.x = unit(1, \"cm\"), legend.margin = margin(0,0,0,0))  + \n  guides(color = guide_legend(nrow = 2, byrow = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.4 Age proportional effects\n\n\nCode\nas_tibble(Mcmcdat[, c(\"p[1]\", \"p[2]\", \"p[3]\", \"p[4]\", \"p[5]\", \"p[6]\", \"p[7]\", \"p[8]\", \"p[9]\", \n                      \"p[10]\", \"p[11]\", \"p[12]\", \"p[13]\", \"p[14]\")]) %&gt;%\n  gather(key = \"param\", value = \"value\") %&gt;% mutate(param = fct_rev(as_factor(param))) %&gt;% \n  ggplot(aes(x = value, y = param, height = stat(density), fill = param)) + \n  geom_density_ridges(scale = 1.3, stat = \"density\", alpha = 0.8) +\n  scale_fill_manual(values = rev(mycols2)) + scale_y_discrete(labels = rev(names.covars.new), expand = expand_scale(mult = c(0.01, .07))) +\n  ylab(\"Environmental driver\") + xlab(expression(paste(\"Proportional effect at age-0 vs. age-1 (\", rho, \")\"))) +\n  theme_bw() + theme(legend.position = \"none\", axis.text = element_text(color = \"black\"), \n        legend.key.spacing.y = unit(0, \"cm\"), legend.key.spacing.x = unit(1, \"cm\"), legend.margin = margin(0,0,0,0), panel.grid = element_blank())  + \n  guides(color = guide_legend(nrow = 2, byrow = TRUE))\n\n\n\n\n\n\n\n\n\nCode\n# same but plot as density/ridgelines\nmycols2 &lt;- c(mycols[1], mycols[1], mycols[1], mycols[1], mycols[1], mycols[1], mycols[2], mycols[2], mycols[3], mycols[3], mycols[3], mycols[3], mycols[4], mycols[4])\n# mycols2 &lt;- c(\"darkorange\", \"darkorange\", bls[3], bls[3], bls[3], bls[3], bls[1], bls[1], \"seagreen\", \"seagreen\", \"seagreen\", \"seagreen\", \"grey50\", \"grey50\")\njpeg(\"Figures/Dot Plots/ReddCounts_Ricker_CovarModel_DensityPlot_ProportionalCov.jpg\", units = \"in\", width = 5, height = 7, res = 1500)\nas_tibble(Mcmcdat[, c(\"p[1]\", \"p[2]\", \"p[3]\", \"p[4]\", \"p[5]\", \"p[6]\", \"p[7]\", \"p[8]\", \"p[9]\", \n                      \"p[10]\", \"p[11]\", \"p[12]\", \"p[13]\", \"p[14]\")]) %&gt;%\n  gather(key = \"param\", value = \"value\") %&gt;% mutate(param = fct_rev(as_factor(param))) %&gt;% \n  ggplot(aes(x = value, y = param, height = stat(density), fill = param)) + \n  geom_density_ridges(scale = 1.3, stat = \"density\", alpha = 0.8) +\n  scale_fill_manual(values = rev(mycols2)) + scale_y_discrete(labels = rev(names.covars.new), expand = expand_scale(mult = c(0.01, .07))) +\n  ylab(\"Environmental driver\") + xlab(expression(paste(\"Proportional effect at age-0 vs. age-1 (\", rho, \")\"))) +\n  theme_bw() + theme(legend.position = \"none\", axis.text = element_text(color = \"black\"), \n        legend.key.spacing.y = unit(0, \"cm\"), legend.key.spacing.x = unit(1, \"cm\"), legend.margin = margin(0,0,0,0), panel.grid = element_blank())  + \n  guides(color = guide_legend(nrow = 2, byrow = TRUE))\ndev.off()\n\n\npng \n  2 \n\n\n\n\n4.6.2.5 Ricker a\n\n\nCode\nggs_caterpillar(D = mod.gg %&gt;% filter(Parameter %in% paste(\"A[\", 1:13, \"]\", sep = \"\")), family = \"A\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + theme_bw() + theme(axis.text = element_text(color = \"black\")) + ylab(\"Population\") + xlab(\"Ricker a\") + scale_y_discrete(labels = rev(popshort), limits = rev)\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.6 River b\n\n\nCode\nggs_caterpillar(D = mod.gg %&gt;% filter(Parameter %in% paste(\"B[\", 1:13, \"]\", sep = \"\")), family = \"B\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + theme_bw() + theme(axis.text = element_text(color = \"black\")) + ylab(\"Population\") + xlab(\"Ricker b\") + scale_y_discrete(labels = rev(popshort), limits = rev)\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.7 Observation error\n\n\nCode\nggs_caterpillar(D = mod.gg, family = \"sigma.oe\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n  theme_bw() + theme(axis.text = element_text(color = \"black\")) + ylab(\"\") + xlab(\"Observation error\") + scale_y_discrete(labels = \"Global\")\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.8 Process error\n\n\nCode\nggs_caterpillar(D = mod.gg, family = \"sigma.pe\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n  theme_bw() + theme(axis.text = element_text(color = \"black\")) + ylab(\"Population\") + xlab(\"Process error\") + scale_y_discrete(labels = rev(popshort), limits = rev)\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.9 Carrying capacity\n\n\nCode\nggs_caterpillar(D = mod.gg, family = \"K\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n  theme_bw() + theme(axis.text = element_text(color = \"black\")) + ylab(\"Population\") + xlab(\"Carrying capacity (redds / km)\") + scale_y_discrete(labels = rev(popshort), limits = rev)\n\n\n\n\n\n\n\n\n\n\n\n4.6.2.10 Phi - autocorrelated residuls\n\n\nCode\nggs_caterpillar(D = mod.gg, family = \"phi\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n  theme_bw() + theme(axis.text = element_text(color = \"black\")) + ylab(\"Population\") + xlab(\"AR1\") + scale_y_discrete(labels = rev(popshort), limits = rev) + geom_vline(xintercept = 0, linetype = \"dashed\") \n\n\n\n\n\n\n\n\n\n\n\n4.6.2.11 Sigma a\n\n\nCode\nggs_caterpillar(D = mod.gg, family = \"sigma.A\", thick_ci = c(0.125, 0.875), thin_ci = c(0.025, 0.975), sort = FALSE) + \n  theme_bw() + theme(axis.text = element_text(color = \"black\")) + ylab(\"\") + xlab(\"\") + geom_vline(xintercept = 0, linetype = \"dashed\") \n\n\n\n\n\n\n\n\n\n\n\n\n4.6.3 Marginal effects\nLoad in covariate mean/SD summaries, to transform axes to real scale\n\n\nCode\ncovsrc_jldq_summary &lt;- read_csv(\"Data/Derived/ManagedFlow_SummaryMeanSD_1967-2022.csv\")\ncovsrc_natq_summary &lt;- read_csv(\"Data/Derived/NaturalFlow_SummaryMeanSD_1975-2022.csv\")\ncovsrc_expq_summary &lt;- read_csv(\"Data/Derived/ExperiencedFlow_SummaryMeanSD_1975-2022.csv\")\ncovsrc_temp_summary &lt;- read_csv(\"Data/Derived/Temperature_SummaryMeanSD_1967-2022.csv\")\ncovsummary &lt;- rbind(covsrc_jldq_summary[c(1,2,6:9),], covsrc_natq_summary[c(6:7),], covsrc_temp_summary)\ncovsummary\n\n\n# A tibble: 12 × 3\n   cov                        mean        sd\n   &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;\n 1 z_jld_rampdur           10.0       5.71  \n 2 z_jld_rampratemindoy   270.        7.92  \n 3 z_jld_winvar             0.0431    0.0649\n 4 z_jld_summean         2700.      838.    \n 5 z_jld_peakmag         5885.     1921.    \n 6 z_jld_peaktime         286.       15.9   \n 7 z_natq_peakmag       10948.     3603.    \n 8 z_natq_peaktime        278.       11.9   \n 9 z_temp_falmean           4.05      1.04  \n10 z_temp_winmean          -9.29      1.80  \n11 z_temp_sprmean           2.38      1.30  \n12 z_temp_summean          14.8       1.14  \n\n\nValues for prediction and color palettes\n\n\nCode\nnvalues &lt;- 100\ncolPal &lt;- hcl.colors(length(pops), \"Spectral\")\n\n\n\nJLD ramp durationJLD ramp timingJLD winter variationJLD summer flowJLD peak flow mag.JLD peak flow timingNat peak flow mag.Nat peak flow timingAutumn temperatureWinter temperatureSpring temperatureSummer temperature\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_jld_rampdur), to = max(dat$z_jld_rampdur), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Duration of ramp down (days)\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$jld_rampdur)\nx.axis &lt;- seq(from = 5, to = 30, by = 5)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[1]) / covsummary$sd[1]\naxis(1, at = x.axis.scaled, labels = x.axis)\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[1]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",1]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"10\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[1])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_jld_rampratemindoy), to = max(dat$z_jld_rampratemindoy), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Timing of ramp down\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$jld_rampratemindoy)\nx.axis &lt;- c(254,264,274)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[2]) / covsummary$sd[2]\naxis(1, at = x.axis.scaled, labels = c(\"10 Sept\", \"20 Sept\", \"30 Sept\"))\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[2]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",2]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"26 Sept\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[2])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_jld_winvar, na.rm = TRUE), to = max(dat$z_jld_winvar, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Mgd. winter flow variation\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$jld_winvar, na.rm = T)\nx.axis &lt;- seq(from = 0, to = 0.3, by = 0.05)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[3]) / covsummary$sd[3]\naxis(1, at = x.axis.scaled, labels = c(\"0.00\", \"0.05\", \"0.10\", \"0.15\", \"0.20\", \"0.25\", \"0.30\"))\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[3]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.225)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",3]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"0.043\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[3])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_jld_summean, na.rm = TRUE), to = max(dat$z_jld_summean, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Mgd. summer mean flow (cfs)\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$jld_summean, na.rm = T)\nx.axis &lt;- seq(from = 1500, to = 4500, by = 1000)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[4]) / covsummary$sd[4]\naxis(1, at = x.axis.scaled, labels = x.axis)\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[4]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",4]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"2700\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[4])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# JLD Peak flow magnitude\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_jld_peakmag, na.rm = TRUE), to = max(dat$z_jld_peakmag, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Mgd. peak flow magnitude (cfs)\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$jld_peakmag, na.rm = T)\nx.axis &lt;- seq(from = 4000, to = 12000, by = 2000)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[5]) / covsummary$sd[5]\naxis(1, at = x.axis.scaled, labels = round((x.axis), digits = 0))\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[5]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",5]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n\n# interaction with natural peak magnitude\n## minimum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[5]\"]*x1 + Mcmcdat[j,\"mu.coef[7]\"]*min(dat$z_natq_peakmag, na.rm = T) + Mcmcdat[j,\"mu.coef[13]\"]*x1*min(dat$z_natq_peakmag, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 3, lwd = 2, type = \"l\")\n## maximum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[5]\"]*x1 + Mcmcdat[j,\"mu.coef[7]\"]*max(dat$z_natq_peakmag, na.rm = T) + Mcmcdat[j,\"mu.coef[13]\"]*x1*max(dat$z_natq_peakmag, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 2, lwd = 2, type = \"l\")\nlegend(\"topright\", legend = c(\"Min. nat. peak flow\", \"Max. nat. peak flow\"), lwd = 2, lty = c(3,2), bty = \"n\", cex = 0.75)\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"5884\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[5])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_jld_peaktime, na.rm = TRUE), to = max(dat$z_jld_peaktime, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Mgd. peak flow timing\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$jld_peaktime, na.rm = T)\nx.axis &lt;- c(242, 273, 303)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[6]) / covsummary$sd[6]\naxis(1, at = x.axis.scaled, labels = c(\"1 May\", \"1 June\", \"1 July\"))\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[6]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",6]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n\n# interaction with natural peak magnitude\n## minimum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[6]\"]*x1 + Mcmcdat[j,\"mu.coef[8]\"]*min(dat$z_natq_peaktime, na.rm = T) + Mcmcdat[j,\"mu.coef[14]\"]*x1*min(dat$z_natq_peaktime, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 3, lwd = 2, type = \"l\")\n## maximum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[6]\"]*x1 + Mcmcdat[j,\"mu.coef[8]\"]*max(dat$z_natq_peaktime, na.rm = T) + Mcmcdat[j,\"mu.coef[14]\"]*x1*max(dat$z_natq_peaktime, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 2, lwd = 2, type = \"l\")\nlegend(\"topleft\", legend = c(\"Min. nat. peak time\", \"Max. nat. peak time\"), lwd = 2, lty = c(3,2), bty = \"n\", cex = 0.75)\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"14 June\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[6])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_natq_peakmag, na.rm = TRUE), to = max(dat$z_natq_peakmag, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Natural peak flow magnitude (cfs)\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$natq_peakmag, na.rm = T)\nx.axis &lt;- seq(from = 5000, to = 20000, by = 5000)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[7]) / covsummary$sd[7]\naxis(1, at = x.axis.scaled, labels = round((x.axis), digits = 0))\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[7]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",7]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n\n# interaction with natural peak magnitude\n## minimum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[7]\"]*x1 + Mcmcdat[j,\"mu.coef[5]\"]*min(dat$z_jld_peakmag, na.rm = T) + Mcmcdat[j,\"mu.coef[13]\"]*x1*min(dat$z_jld_peakmag, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 3, lwd = 2, type = \"l\")\n## maximum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[7]\"]*x1 + Mcmcdat[j,\"mu.coef[5]\"]*max(dat$z_jld_peakmag, na.rm = T) + Mcmcdat[j,\"mu.coef[13]\"]*x1*max(dat$z_jld_peakmag, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 2, lwd = 2, type = \"l\")\nlegend(\"topright\", legend = c(\"Min. JLD peak flow\", \"Max. JLD peak flow\"), lwd = 2, lty = c(3,2), bty = \"n\", cex = 0.75)\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"10948\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[7])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_natq_peaktime, na.rm = TRUE), to = max(dat$z_natq_peaktime, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = \"Natural peak flow timing\", ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$natq_peaktime, na.rm = T)\nx.axis &lt;- c(256, 273, 287, 303)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[8]) / covsummary$sd[8]\naxis(1, at = x.axis.scaled, labels = c(\"15 May\", \"1 June\", \"15 June\", \"1 July\"))\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[8]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",8]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n\n# interaction with natural peak timing\n## minimum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[8]\"]*x1 + Mcmcdat[j,\"mu.coef[6]\"]*min(dat$z_jld_peaktime, na.rm = T) + Mcmcdat[j,\"mu.coef[14]\"]*x1*min(dat$z_jld_peaktime, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 3, lwd = 2, type = \"l\")\n## maximum\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[8]\"]*x1 + Mcmcdat[j,\"mu.coef[6]\"]*max(dat$z_jld_peaktime, na.rm = T) + Mcmcdat[j,\"mu.coef[14]\"]*x1*max(dat$z_jld_peaktime, na.rm = T) }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \nlines(pred_median ~ x1, lty = 2, lwd = 2, type = \"l\")\nlegend(\"topright\", legend = c(\"Min. JLD peak time\", \"Max. JLD peak time\"), lwd = 2, lty = c(3,2), bty = \"n\", cex = 0.75)\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"5 June\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[8])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_temp_falmean, na.rm = TRUE), to = max(dat$z_temp_falmean, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = expression(paste(\"Autumn temperature (\"^\"o\", \"C)\", sep = \"\")), ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$temp_falmean, na.rm = T)\nx.axis &lt;- seq(from = 2, to = 6, by = 1)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[9]) / covsummary$sd[9]\naxis(1, at = x.axis.scaled, labels = x.axis)\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[9]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.05)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",9]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"4.05\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[9])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_temp_winmean, na.rm = TRUE), to = max(dat$z_temp_winmean, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = expression(paste(\"Winter temperature (\"^\"o\", \"C)\", sep = \"\")), ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$temp_winmean, na.rm = T)\nx.axis &lt;- seq(from = -13, to = 5, by = 2)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[10]) / covsummary$sd[10]\naxis(1, at = x.axis.scaled, labels = x.axis)\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[10]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.925)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",10]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"-9.29\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[10])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_temp_sprmean, na.rm = TRUE), to = max(dat$z_temp_sprmean, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = expression(paste(\"Spring temperature (\"^\"o\", \"C)\", sep = \"\")), ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$temp_sprmean, na.rm = T)\nx.axis &lt;- seq(from = 0, to = 5, by = 1)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[11]) / covsummary$sd[11]\naxis(1, at = x.axis.scaled, labels = x.axis)\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[11]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",11]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"2.38\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[11])\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(4,4,2.5,0.5), mgp = c(2.25,0.8,0))\n# set up plot\nx1 &lt;- seq(from = min(dat$z_temp_summean, na.rm = TRUE), to = max(dat$z_temp_summean, na.rm = TRUE), length.out = nvalues)\nplot(seq(from = 0.3, to = 2, length.out = nvalues) ~ x1, pch = NA, bty = \"l\", xlab = expression(paste(\"Summer temperature (\"^\"o\", \"C)\", sep = \"\")), ylab = \"Productivity, ln(R/S)\", axes = F)\n# axes and box\n# range(dat$temp_summean, na.rm = T)\nx.axis &lt;- seq(from = 12, to = 17, by = 1)\nx.axis.scaled &lt;- (x.axis - covsummary$mean[12]) / covsummary$sd[12]\naxis(1, at = x.axis.scaled, labels = x.axis)\naxis(2)\n# predictions\npred &lt;- matrix(NA, nrow = nrow(Mcmcdat), ncol = nvalues)\nfor (j in 1:nrow(pred)) { pred[j,] &lt;- Mcmcdat[j,\"mu.A\"] + Mcmcdat[j,\"mu.coef[12]\"]*x1 }\npred_median &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.50) \npred_025 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.025)\npred_125 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.125)\npred_875 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.875)\npred_975 &lt;- apply(pred, MARGIN = 2, quantile, prob = 0.975)\npolygon(c(x1, rev(x1)), c(pred_975, rev(pred_025)), col = \"grey85\", lty=0)\npolygon(c(x1, rev(x1)), c(pred_875, rev(pred_125)), col = \"grey70\", lty=0)\n# add population-specific fits\n# for (i in 1:n.pops) { lines(param.summary[paste(\"A[\", i, \"]\", sep = \"\"),5] + param.summary[paste(\"coef[\", i, \",12]\", sep = \"\"),5]*x1 ~ x1, col = colPal[i], lwd = 1) }\n# add global fit\nlines(pred_median ~ x1, col = \"black\", lwd = 3, type = \"l\")\n# median productivity\nabline(h = param.summary[\"mu.A\",5], lty = 3, col = \"grey40\")\nabline(v = 0, lty = 3, col = \"grey40\")\ntext(x = 0, y = 0.3, labels = \"14.81\", pos = 4, col = \"grey40\")\n# lines(density((median(Mcmcdat[,\"mu.A\"]) - Mcmcdat[,\"mu.A\"]) / Mcmcdat[,\"mu.coef[1]\"]))\n# legend\npar(xpd = TRUE, usr = c(0,1,0,1))\n# legend(0.085, 1.15, legend = popshort, lwd = 1, col = colPal, ncol = 5, cex = 0.5, bg = \"grey85\")\nbox(bty = \"o\", lwd = 3, col = mycols2[12])\n\n\n\n\n\n\n\n\n\n\n\n\nWrite plots to file…\n\n\n4.6.4 Interactions\nGet raw covariate data for plotting\n\n\nCode\nmgdcovs &lt;- read_csv(\"Data/Derived/JLD_ManagedFlow_Covariates_BroodYear_1960-2022.csv\") %&gt;% \n  select(broodyr, jld_peakmag, jld_peaktime) %&gt;%\n  mutate(z_jld_peakmag = (jld_peakmag - covsummary$mean[5])/covsummary$sd[5],\n         z_jld_peaktime = (jld_peaktime - covsummary$mean[6])/covsummary$sd[6])\n\nnatcovs &lt;- read_csv(\"Data/Derived/SnakeTribs_NaturalFlow_Covariates_BroodYear_1960-2022.csv\") %&gt;% \n  filter(site == \"SnakeNat\") %&gt;% \n  select(broodyr, natq_peakmag, natq_peaktime) %&gt;%\n  mutate(z_natq_peakmag = (natq_peakmag - covsummary$mean[7])/covsummary$sd[7],\n         z_natq_peaktime = (natq_peaktime - covsummary$mean[8])/covsummary$sd[8])\n\nmycovdat &lt;- mgdcovs %&gt;% left_join(natcovs)\n\n\nNumber of values for calculation\n\n\nCode\nnvalues &lt;- 100\n\n\n\n4.6.4.1 Peak flow magnitude\nGenerate sequences of predictor data and transform to original scale\n\n\nCode\nxjld &lt;- seq(from = min(dat$z_jld_peakmag, na.rm = TRUE), to = max(dat$z_jld_peakmag, na.rm = TRUE), length.out = nvalues)\nxnat &lt;- seq(from = min(dat$z_natq_peakmag, na.rm = TRUE), to = max(dat$z_natq_peakmag, na.rm = TRUE), length.out = nvalues)\nxjld.real &lt;- (xjld * covsummary$sd[5]) + covsummary$mean[5]\nxnat.real &lt;- (xnat * covsummary$sd[7]) + covsummary$mean[7]\n\n\nSet up axes\n\n\nCode\nxjld.axis &lt;- seq(from = 4000, to = 12000, by = 2000)\nxjld.axis.scaled &lt;- (xjld.axis - covsummary$mean[5]) / covsummary$sd[5]\n\nxnat.axis &lt;- seq(from = 5000, to = 20000, by = 5000)\nxnat.axis.scaled &lt;- (xnat.axis - covsummary$mean[7]) / covsummary$sd[7]\n\n\nPredict productivity from model\n\n\nCode\nz &lt;- matrix(data = NA, nrow = nvalues, ncol = nvalues) # matrix of predictions\ncom &lt;- matrix(data = NA, nrow = nvalues, ncol = nvalues) # matrix of combined flow\nfor(i in 1:nvalues) {\n  for(j in 1:nvalues) {\n    z[i,j] &lt;- param.summary[\"mu.coef[5]\",5]*xjld[i] + param.summary[\"mu.coef[7]\",5]*xnat[j] + param.summary[\"mu.coef[13]\",5]*xjld[i]*xnat[j]\n    com[i,j] &lt;- (xjld.real[i]) + (xnat.real[j])\n  }\n  }\nz.cont &lt;- ifelse(z &lt; 0, 0, z) # trick for plotting single contour\nrange(z)\n\n\n[1] -0.2687132  0.1940241\n\n\nPlot set up\n\n\nCode\nmylevels &lt;- seq(-1, 1, by = 0.1) # specify location and number of breaks for plotting\nmycols &lt;- rev(hcl.colors(length(mylevels)-1, \"Blue-Red 3\"))\nmyddd &lt;- mycovdat %&gt;% select(z_natq_peakmag, z_jld_peakmag) %&gt;% filter(!is.na(z_natq_peakmag))\nmyhull &lt;- chull(myddd)\n\n\n\n\nCode\npar(mar = c(5,5,1,1), mgp = c(3.5,1,0))\nfilled.contour(x = xnat, y = xjld, z = t(z),\n               plot.title = {\n                 title(xlab = \"Natural peak flow magnitude (cfs)\")\n                 title(ylab = \"Managed peak flow magnitude (cfs)\")\n               },\n               levels = mylevels,\n               col = mycols,\n               plot.axes = {\n                 contour(x = xnat, y = xjld, z = t(z), levels = 0, lty = 3, lwd = 1, col = \"grey40\",\n                         drawlabels = F, axes = F, frame.plot = F, add = T);\n                 segments(myddd$z_natq_peakmag[myhull], myddd$z_jld_peakmag[myhull],\n                          myddd$z_natq_peakmag[c(myhull[length(myhull)], myhull[-length(myhull)])],\n                          myddd$z_jld_peakmag[c(myhull[length(myhull)], myhull[-length(myhull)])],\n                          col = \"grey40\", lwd = 2) # Draw convex hull lines\n                 axis(1, at = xnat.axis.scaled, labels = xnat.axis); \n                 axis(2, at = xjld.axis.scaled, labels = xjld.axis)\n               })\n\n\n\n\n\n\n\n\n\n\n\n4.6.4.2 Peak flow timing\nGenerate sequences of predictor data and transform to original scale\n\n\nCode\nxjld &lt;- seq(from = min(dat$z_jld_peaktime, na.rm = TRUE), to = max(dat$z_jld_peaktime, na.rm = TRUE), length.out = nvalues)\nxnat &lt;- seq(from = min(dat$z_natq_peaktime, na.rm = TRUE), to = max(dat$z_natq_peaktime, na.rm = TRUE), length.out = nvalues)\nxjld.real &lt;- (xjld * covsummary$sd[6]) + covsummary$mean[6]\nxnat.real &lt;- (xnat * covsummary$sd[8]) + covsummary$mean[8]\n\n\nSet up axes\n\n\nCode\nxjld.axis &lt;- c(242, 273, 303)\nxjld.axis.scaled &lt;- (xjld.axis - covsummary$mean[6]) / covsummary$sd[6]\nxjld.axis.labels &lt;- c(\"1 May\", \"1 June\", \"1 July\")\n\nxnat.axis &lt;- c(256, 273, 287, 303)\nxnat.axis.scaled &lt;- (xnat.axis - covsummary$mean[8]) / covsummary$sd[8]\nxnat.axis.labels &lt;- c(\"15 May\", \"1 June\", \"15 June\", \"1 July\")\n\n\nPredict productivity from model\n\n\nCode\nz &lt;- matrix(data = NA, nrow = nvalues, ncol = nvalues) # matrix of predictions\ncom &lt;- matrix(data = NA, nrow = nvalues, ncol = nvalues) # matrix of combined flow\nfor(i in 1:nvalues) {\n  for(j in 1:nvalues) {\n    z[i,j] &lt;- param.summary[\"mu.coef[6]\",5]*xjld[i] + param.summary[\"mu.coef[8]\",5]*xnat[j] + param.summary[\"mu.coef[14]\",5]*xjld[i]*xnat[j]\n  }\n  }\nz.cont &lt;- ifelse(z &lt; 0, 0, z) # trick for plotting single contour\nrange(z)\n\n\n[1] -0.7522073  0.8330047\n\n\nPlot set up\n\n\nCode\nmylevels &lt;- seq(-1, 1, by = 0.1) # specify location and number of breaks for plotting\nmycols &lt;- rev(hcl.colors(length(mylevels)-1, \"Blue-Red 3\"))\nmyddd &lt;- mycovdat %&gt;% select(z_natq_peaktime, z_jld_peaktime) %&gt;% filter(!is.na(z_natq_peaktime), !is.na(z_jld_peaktime))\nmyhull &lt;- chull(myddd)\n\n\n\n\nCode\npar(mar = c(5,5,1,1), mgp = c(3.5,1,0))\nfilled.contour(x = xnat, y = xjld, z = t(z),\n               plot.title = {\n                 title(xlab = \"Natural peak flow timing\")\n                 title(ylab = \"Managed peak flow timing\")\n               },\n               levels = mylevels,\n               col = mycols,\n               plot.axes = {\n                 contour(x = xnat, y = xjld, z = t(z), levels = 0, lty = 3, lwd = 1, col = \"grey40\",\n                         drawlabels = F, axes = F, frame.plot = F, add = T);\n                 segments(myddd$z_natq_peaktime[myhull], myddd$z_jld_peaktime[myhull],\n                          myddd$z_natq_peaktime[c(myhull[length(myhull)], myhull[-length(myhull)])],\n                          myddd$z_jld_peaktime[c(myhull[length(myhull)], myhull[-length(myhull)])],\n                          col = \"grey40\", lwd = 2) # Draw convex hull lines\n                 axis(1, at = xnat.axis.scaled, labels = xnat.axis.labels);\n                 axis(2, at = xjld.axis.scaled, labels = xjld.axis.labels)\n               })",
    "crumbs": [
      "Modeling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Stock-Recruitment Analysis</span>"
    ]
  },
  {
    "objectID": "ClimateProjectionData.html",
    "href": "ClimateProjectionData.html",
    "title": "5  Future Climate Projections",
    "section": "",
    "text": "5.1 Generate seasonal projections\nPurpose: Generate future seasonal mean air temperature projections from GCM data (Rahimi et al. 2024, Geoscientific Model Development)\nSome misc. objects\nCode\npatt &lt;- c(\"t2min_atStation_corrected\", \"t2max_atStation_corrected\", \"t2min_atStation_original\", \"t2max_atStation_original\")\nsumm &lt;- c(\"min\", \"max\", \"min\", \"max\")\ntype &lt;- c(\"corrected\", \"corrected\", \"original\", \"original\")\nmylist &lt;- list()\nPull in climate projection data\nCode\nfor(i in 1:length(patt)) {\n  myfiles &lt;- list.files(\"Data/GCM Archive\", pattern = patt[i], full.names = TRUE)\n  dat &lt;- read_csv(myfiles, id = \"file_name\")[,c(1,2,5)] %&gt;% mutate(summ = summ[i], type = type[i], gcm = str_match(file_name, \"Archive/\\\\s*(.*?)\\\\s*_t2\")[,2])\n  dat &lt;- dat %&gt;% select(6,4,5,2,3) %&gt;% rename(date = 4, temp = 5)\n  mylist[[i]] &lt;- dat\n  #print(i)\n}\ndat &lt;- do.call(rbind, mylist)\nsummary(dat)\n\n\n     gcm                summ               type                date           \n Length:2604648     Length:2604648     Length:2604648     Min.   :1980-10-01  \n Class :character   Class :character   Class :character   1st Qu.:2010-07-01  \n Mode  :character   Mode  :character   Mode  :character   Median :2040-04-01  \n                                                          Mean   :2040-03-31  \n                                                          3rd Qu.:2069-12-31  \n                                                          Max.   :2099-09-30  \n                                                          NA's   :836         \n      temp      \n Min.   :217.5  \n 1st Qu.:269.5  \n Median :276.6  \n Mean   :277.9  \n 3rd Qu.:286.6  \n Max.   :315.6  \n                \n\n\nCode\nhead(dat)\n\n\n# A tibble: 6 × 5\n  gcm                 summ  type      date        temp\n  &lt;chr&gt;               &lt;chr&gt; &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;\n1 access-cm2_r5i1p1f1 min   corrected 1980-10-01  268.\n2 access-cm2_r5i1p1f1 min   corrected 1980-10-02  257.\n3 access-cm2_r5i1p1f1 min   corrected 1980-10-03  253.\n4 access-cm2_r5i1p1f1 min   corrected 1980-10-04  260.\n5 access-cm2_r5i1p1f1 min   corrected 1980-10-05  267.\n6 access-cm2_r5i1p1f1 min   corrected 1980-10-06  271.\nNotes:\nCode\nview(dat %&gt;% group_by(gcm, summ, type) %&gt;% summarise(mind = min(date, na.rm = T), maxd = max(date, na.rm = T), n = n()))\nSome GCMs do not predict for Feb 29 (leap years)…drop NAs\nCode\ndat &lt;- dat %&gt;% filter(!is.na(date))\nFind daily mean temp for each climate model\nCode\ndat2 &lt;- dat %&gt;% group_by(gcm, type, date) %&gt;% summarize(temp_mean = mean(temp)-273.15) %&gt;% ungroup()\ndat2 %&gt;% group_by(gcm) %&gt;% summarise(mind = min(date), maxd = max(date), n = n())\n\n\n# A tibble: 15 × 4\n   gcm                    mind       maxd           n\n   &lt;chr&gt;                  &lt;date&gt;     &lt;date&gt;     &lt;int&gt;\n 1 access-cm2_r5i1p1f1    1980-10-01 2099-09-30 86928\n 2 canesm5_r1i1p2f1       1980-10-01 2099-09-30 86870\n 3 cesm2_r11i1p1f1        1980-10-01 2099-09-30 86870\n 4 cnrm-esm2-1_r1i1p1f2   1980-10-01 2099-09-30 86928\n 5 ec-earth3-veg_r1i1p1f1 1980-10-01 2099-09-30 86928\n 6 ec-earth3_r1i1p1f1     1980-10-01 2099-09-30 86928\n 7 fgoals-g3_r1i1p1f1     1980-10-01 2099-09-30 86870\n 8 giss-e2-1-g_r1i1p1f2   1980-10-01 2099-09-30 86870\n 9 miroc6_r1i1p1f1        1980-10-01 2099-09-30 86928\n10 mpi-esm1-2-hr_r3i1p1f1 1980-10-01 2099-09-30 86928\n11 mpi-esm1-2-hr_r7i1p1f1 1980-10-01 2099-09-30 86928\n12 mpi-esm1-2-lr_r7i1p1f1 1980-10-01 2099-09-30 86928\n13 noresm2-mm_r1i1p1f1    1980-10-01 2099-09-30 86870\n14 taiesm1_r1i1p1f1       1980-10-01 2099-09-30 86870\n15 ukesm1-0-ll_r2i1p1f2   1980-10-01 2099-09-30 85262\n\n\nCode\n#sum(is.na(dat2$temp_mean))",
    "crumbs": [
      "Projections",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Future Climate Projections</span>"
    ]
  },
  {
    "objectID": "ClimateProjectionData.html#generate-seasonal-projections",
    "href": "ClimateProjectionData.html#generate-seasonal-projections",
    "title": "5  Future Climate Projections",
    "section": "",
    "text": "Some GCMs do not predict for Feb 29 (leap years)\nukesm1-0-ll_r2i1p1f2 predicts for 30 days per month, even in Feb (but does not actually have dates for Feb 29/30)\n\n\n\n\n\n\n\n5.1.1 Vizualize raw GCM data\nGroup by year, plot time series of annual means.\n\n\nCode\ndat2 %&gt;% mutate(year = year(date)) %&gt;% group_by(gcm, year) %&gt;% summarize(ann_temp = mean(temp_mean)) %&gt;% ggplot() + geom_line(aes(x = year, y = ann_temp, group = gcm, colour = gcm))\n\n\n\n\n\n\n\n\n\nView corrected daily (mean) air temp for a single year (1981)\n\n\nCode\ndat2 %&gt;% filter(date &gt;= \"1981-01-01\" & date &lt;= \"1981-12-31\", type == \"corrected\") %&gt;% ggplot() + geom_line(aes(x = date, y = temp_mean, group = gcm, colour = gcm))\n\n\n\n\n\n\n\n\n\n\n\n5.1.2 Summarize across seasons\nSummarize GCM data across four seasons\n\n\nCode\ndat2 &lt;- dat2 %&gt;% mutate(season = ifelse(month(date) %in% c(9,10,11), \"fal\",\n                                        ifelse(month(date) %in% c(12,1,2), \"win\",\n                                               ifelse(month(date) %in% c(3,4,5), \"spr\", \"sum\"))))\ndat3 &lt;- dat2 %&gt;% group_by(gcm, type, season, year(date)) %&gt;% summarize(temp_mean = mean(temp_mean)) %&gt;% rename(year = 4)\n\n\nPlot time series of seasonal mean air temperature:\n\n\nCode\ndat3 %&gt;% ggplot() + geom_line(aes(x = year, y = temp_mean, group = gcm, colour = gcm)) + facet_wrap(~season)\n\n\n\n\n\n\n\n\n\n\n\n5.1.3 Summarize across GCMs\nSummarize seasonal mean air temperature across 15 GCMs\n\n\nCode\ndat_summ &lt;- dat3 %&gt;% group_by(type, season, year) %&gt;% summarize(count = n(), temp_avg = mean(temp_mean, na.rm = T), temp_sd = sd(temp_mean, na.rm = T), temp_min = min(temp_mean, na.rm = T), temp_max = max(temp_mean, na.rm = T)) %&gt;% ungroup()\n\n\nPlot raw and corrected output: mean min and max\n\n\nCode\ndat_summ %&gt;% ggplot() + geom_line(aes(x = year, y = temp_avg)) + geom_line(aes(x = year, y = temp_min), color = 4) + geom_line(aes(x = year, y = temp_max), color = 2) + facet_wrap(~season + type)\n\n\n\n\n\n\n\n\n\nView winter corrected only:\n\n\nCode\ndat_summ %&gt;% filter(season == \"win\", type == \"corrected\") %&gt;% ggplot() + geom_line(aes(x = year, y = temp_avg)) + geom_line(aes(x = year, y = temp_min), linetype = 2) + geom_line(aes(x = year, y = temp_max), linetype = 2) \n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Write out data files\n\n\nCode\nwrite_csv(dat3, \"Data/Derived/SeasonalMeanAirTemp_byGCM_1980-2099.csv\")\nwrite_csv(dat_summ, \"Data/Derived/SeasonalMeanAirTemp_Summarized_1980-2099.csv\")\n\n\n\n\n5.1.5 Read derived data\n\n\nCode\ndat3 &lt;- read_csv(\"Data/Derived/SeasonalMeanAirTemp_byGCM_1980-2099.csv\")\ndat_summ &lt;- read_csv(\"Data/Derived/SeasonalMeanAirTemp_Summarized_1980-2099.csv\")",
    "crumbs": [
      "Projections",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Future Climate Projections</span>"
    ]
  },
  {
    "objectID": "ClimateProjectionData.html#compare-to-observed-data",
    "href": "ClimateProjectionData.html#compare-to-observed-data",
    "title": "5  Future Climate Projections",
    "section": "5.2 Compare to observed data",
    "text": "5.2 Compare to observed data\nLoad NWS air temperature data from Moose, WY\n\n\nCode\nairsum &lt;- read_csv(\"Data/Derived/AirTemperature_Covariates_BroodYear_1960-2022.csv\")\n\n\nCompare observed data with projections from individual GCMs\n\nAutumnWinterSpringSummer\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat3 %&gt;% filter(season == \"fal\"), aes(x = year, y = temp_mean, group = gcm, colour = gcm)) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_falmean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat3 %&gt;% filter(season == \"win\"), aes(x = year, y = temp_mean, group = gcm, colour = gcm)) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_winmean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat3 %&gt;% filter(season == \"spr\"), aes(x = year, y = temp_mean, group = gcm, colour = gcm)) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_sprmean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat3 %&gt;% filter(season == \"sum\"), aes(x = year, y = temp_mean, group = gcm, colour = gcm)) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_summean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nCompare observed data with projections summarized across all GCMs\n\nAutumnWinterSpringSummer\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat_summ %&gt;% filter(season == \"fal\"), aes(x = year, y = temp_avg)) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"fal\"), aes(x = year, y = temp_min), color = 4) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"fal\"), aes(x = year, y = temp_max), color = 2) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_falmean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat_summ %&gt;% filter(season == \"win\"), aes(x = year, y = temp_avg)) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"win\"), aes(x = year, y = temp_min), color = 4) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"win\"), aes(x = year, y = temp_max), color = 2) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_winmean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat_summ %&gt;% filter(season == \"spr\"), aes(x = year, y = temp_avg)) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"spr\"), aes(x = year, y = temp_min), color = 4) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"spr\"), aes(x = year, y = temp_max), color = 2) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_sprmean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot() + \n  geom_line(data = dat_summ %&gt;% filter(season == \"sum\"), aes(x = year, y = temp_avg)) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"sum\"), aes(x = year, y = temp_min), color = 4) + \n  geom_line(data = dat_summ %&gt;% filter(season == \"sum\"), aes(x = year, y = temp_max), color = 2) +\n  geom_line(data = airsum %&gt;% filter(site == \"moose\"), aes(x = broodyr, y = temp_summean), size = 1.2) + xlim(1960,2100) +\n  facet_wrap(~ type, ncol = 2) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nCombined plot for supplementary file",
    "crumbs": [
      "Projections",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Future Climate Projections</span>"
    ]
  },
  {
    "objectID": "ClimateProjectionData.html#exceedance-timeline",
    "href": "ClimateProjectionData.html#exceedance-timeline",
    "title": "5  Future Climate Projections",
    "section": "5.3 Exceedance timeline",
    "text": "5.3 Exceedance timeline\nWhen will projected seasonal means consistently exceed observed data (w/in the time frame of redd count monitoring)?\n\nAutumn: 2045-2050\nWinter: 2083\nSpring: 2065\nSummer: 2050-2055\n\n\n\nCode\nmaxobs &lt;- airsum %&gt;% filter(site == \"moose\", broodyr %in% c(1980:2015)) %&gt;% group_by(site) %&gt;% summarise(maxfal = max(temp_falmean, na.rm = T), maxwin = max(temp_winmean, na.rm = T), maxspr = max(temp_sprmean, na.rm = T), maxsum = max(temp_summean, na.rm = T))\n\ndat_summ %&gt;% filter(type == \"corrected\", season == \"fal\", temp_avg &gt;= c(maxobs[1,2])) # 2045-2050\n\n\n# A tibble: 56 × 8\n   type      season  year count temp_avg temp_sd temp_min temp_max\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 corrected fal     2036    15     6.18   0.994     4.82     7.75\n 2 corrected fal     2042    15     6.21   1.11      4.34     7.88\n 3 corrected fal     2043    15     6.62   1.23      4.51     8.71\n 4 corrected fal     2046    15     6.29   1.62      3.64    10.1 \n 5 corrected fal     2047    15     6.63   1.24      5.16    10.0 \n 6 corrected fal     2049    15     6.71   1.54      3.29     9.42\n 7 corrected fal     2050    15     6.34   1.31      4.42     9.01\n 8 corrected fal     2051    15     6.25   1.85      2.83     9.07\n 9 corrected fal     2052    15     6.50   1.81      1.99    10.1 \n10 corrected fal     2053    15     6.88   1.32      4.98    10.2 \n# ℹ 46 more rows\n\n\nCode\ndat_summ %&gt;% filter(type == \"corrected\", season == \"win\", temp_avg &gt;= c(maxobs[1,3])) # 2083\n\n\n# A tibble: 16 × 8\n   type      season  year count temp_avg temp_sd temp_min temp_max\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 corrected win     2083    15    -5.10    1.62    -7.54   -1.86 \n 2 corrected win     2084    15    -5.52    1.92    -8.86   -2.59 \n 3 corrected win     2085    15    -5.63    1.84    -9.09   -2.57 \n 4 corrected win     2086    15    -5.58    2.06    -7.68   -0.963\n 5 corrected win     2088    15    -5.00    1.71    -7.36   -1.47 \n 6 corrected win     2089    15    -5.68    1.77    -8.32   -2.08 \n 7 corrected win     2090    15    -5.73    2.53   -11.2    -1.29 \n 8 corrected win     2091    15    -5.20    2.25    -9.76   -1.64 \n 9 corrected win     2092    15    -5.54    2.28   -10.7    -0.699\n10 corrected win     2093    15    -4.81    2.05    -7.88   -0.445\n11 corrected win     2094    15    -5.70    1.47    -7.95   -2.92 \n12 corrected win     2095    15    -5.34    1.99    -8.69   -2.11 \n13 corrected win     2096    15    -4.91    2.21    -8.06    0.928\n14 corrected win     2097    15    -5.34    1.38    -7.22   -3.64 \n15 corrected win     2098    15    -4.97    2.30    -8.54   -1.71 \n16 corrected win     2099    15    -5.05    2.97   -12.3     0.517\n\n\nCode\ndat_summ %&gt;% filter(type == \"corrected\", season == \"spr\", temp_avg &gt;= c(maxobs[1,4])) # 2065\n\n\n# A tibble: 37 × 8\n   type      season  year count temp_avg temp_sd temp_min temp_max\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 corrected spr     2060    15     5.45    2.16     1.08     9.80\n 2 corrected spr     2061    15     5.55    1.28     1.89     7.24\n 3 corrected spr     2065    15     5.54    1.47     3.15     8.73\n 4 corrected spr     2066    15     5.76    2.03     1.27     8.69\n 5 corrected spr     2067    15     5.66    1.67     2.06     8.41\n 6 corrected spr     2068    15     5.47    1.46     3.52     8.27\n 7 corrected spr     2069    15     5.52    1.90     2.03     8.60\n 8 corrected spr     2070    15     5.76    1.93     1.93     9.33\n 9 corrected spr     2071    15     6.12    1.84     2.84     8.98\n10 corrected spr     2072    15     6.40    2.12     2.76    11.3 \n# ℹ 27 more rows\n\n\nCode\ndat_summ %&gt;% filter(type == \"corrected\", season == \"sum\", temp_avg &gt;= c(maxobs[1,5])) # 2050-2055\n\n\n# A tibble: 48 × 8\n   type      season  year count temp_avg temp_sd temp_min temp_max\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 corrected sum     2050    15     17.4   0.891     16.1     19.4\n 2 corrected sum     2051    15     17.5   1.48      15.3     20.5\n 3 corrected sum     2053    15     17.6   0.926     16.0     19.3\n 4 corrected sum     2055    15     17.6   1.37      15.7     20.7\n 5 corrected sum     2056    15     17.7   1.17      15.5     19.7\n 6 corrected sum     2057    15     17.6   1.06      15.7     19.3\n 7 corrected sum     2058    15     17.5   1.27      16.4     20.4\n 8 corrected sum     2059    15     18.0   1.23      15.1     20.3\n 9 corrected sum     2060    15     17.8   1.33      16.0     20.4\n10 corrected sum     2061    15     18.1   1.13      16.2     20.3\n# ℹ 38 more rows",
    "crumbs": [
      "Projections",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Future Climate Projections</span>"
    ]
  }
]